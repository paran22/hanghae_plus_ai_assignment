{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.3.24)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (1.75.0)\n",
      "Requirement already satisfied: chromadb in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.6.3)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (2.6.0)\n",
      "Collecting langchain_huggingface\n",
      "  Using cached langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (0.3.55)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (0.3.32)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.115.12)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (3.25.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.21.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (3.10.16)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_huggingface) (0.30.2)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_huggingface) (4.1.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_huggingface) (4.51.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: packaging>=19.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.46.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.39.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.15.2)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.2.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Using cached langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: langchain_huggingface\n",
      "Successfully installed langchain_huggingface-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv pandas langchain openai chromadb torch langchain_huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGë¡œ ì‚¬ìš©í•  ë°ì´í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ë„ì„œ ì •ë³´ ë°ì´í„°\n",
    "\n",
    "ë°ì´í„°ëŠ” ê³µê³µAPIì—ì„œ ì œê³µí•˜ëŠ” [êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ ì‚¬ì„œì¶”ì²œë„ì„œëª©ë¡](https://www.nl.go.kr/NL/contents/N31101030900.do)ì„ ì‚¬ìš©í•œë‹¤.\n",
    "\n",
    "xml ë°ì´í„°ë¥¼ json ë°ì´í„°ë¡œ ë³€í™˜í•˜ì˜€ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ“š ë°ì´í„° êµ¬ì¡°\n",
      "==================================================\n",
      "\n",
      "ğŸ“ ë°ì´í„° í‚¤ ëª©ë¡:\n",
      "category_code, category_name, title, author, publisher, isbn, contents, table_of_contents, publish_year, recommend_year, recommend_month\n",
      "\n",
      "ğŸ“ ì²« ë²ˆì§¸ ë„ì„œ ìƒì„¸ ì •ë³´:\n",
      "\n",
      "category_code:\n",
      "    6\n",
      "\n",
      "category_name:\n",
      "    ì¸ë¬¸ê³¼í•™\n",
      "\n",
      "title:\n",
      "    ì œëŒ€ë¡œ ì—°ìŠµí•˜ëŠ” ë²• : ì–´í•™ë¶€í„° ìŠ¤í¬ì¸ ê¹Œì§€, ì¸ì§€ì‹¬ë¦¬í•™ì´ ì œì‹œí•˜ëŠ” ë°°ì›€ì˜ ê¸°ìˆ \n",
      "\n",
      "author:\n",
      "    ì•„íˆ¬ë¡œ E. í—ˆë‚¸ë°ì¦ˆ ì§€ìŒ ;ë°©ì§„ì´ ì˜®ê¹€\n",
      "\n",
      "publisher:\n",
      "    ë¶íŠ¸ë¦¬ê±° ì§€í•™ì‚¬\n",
      "\n",
      "isbn:\n",
      "    9791193378335\n",
      "\n",
      "contents:\n",
      "    í•œë•Œ ìœ í–‰í–ˆë˜ ì¼ë§Œ ì‹œê°„ì˜ ë²•ì¹™ì„ ê¸°ì–µí•˜ëŠ”ê°€? ì–´ë–¤ ë¶„ì•¼ì—ì„œ ì „ë¬¸ê°€ê°€ ë˜ë ¤ë©´ ìµœì†Œí•œ ì¼ë§Œ ì‹œê°„ì˜ í›ˆë ¨ì´ í•„ìš”í•˜ë‹¤ëŠ” ê°œë…ì´ë‹¤. í•˜ì§€ë§Œ ë‹¨ìˆœíˆ ì—°ìŠµì˜ ì–‘ì´ ë§ë‹¤ê³  í•´ì„œ ëª¨ë‘ê°€ ì „ë¬¸ê°€ê°€\n",
      " ë˜ëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤. ì´ ì±…ì€ ì‹¬ë¦¬í•™ìì´ì ë‹¤ì¤‘ì–¸ì–´ êµ¬ì‚¬ì, í…Œë‹ˆìŠ¤ ì„ ìˆ˜ë¡œë„ í™œì•½í–ˆë˜ ì €ìê°€ í•™ìŠµê³¼ í›ˆë ¨, ê·¸ë¦¬ê³  ê¸°ëŸ‰ í–¥ìƒì˜ ìƒê´€ê´€ê³„ë¥¼ ì—°êµ¬í•œ ê²°ê³¼ë¥¼ ë‹´ê³  ìˆë‹¤. ì¥ í”¼ì•„ì œ, ë…¸\n",
      "ì—„ ì´˜ìŠ¤í‚¤, ê·¸ë¦¬ê³  ì¼ë§Œ ì‹œê°„ì˜ ë²•ì¹™ì„ ì œì°½í•œ ì‹¬ë¦¬í•™ì ì•ˆë°ë¥´ìŠ¤ ì—ë¦­ì† ë“± ëŒ€ê°€ë“¤ì˜ ì´ë¡  ë° ìµœì‹  ì—°êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‡Œê³¼í•™ê³¼ ì¸ì§€ì‹¬ë¦¬í•™ì  ê´€ì ì—ì„œ 'ì œëŒ€ë¡œ ì—°ìŠµí•˜ëŠ” ë²•'ì„ íƒ\n",
      "êµ¬í•œë‹¤. ì•„ë§ˆì¶”ì–´ ìŠ¤í¬ì¸  ì„ ìˆ˜, ìœ ëª… ì²´ìŠ¤ ì„ ìˆ˜, ë‹¤ì¤‘ì–¸ì–´ êµ¬ì‚¬ì, í”¼ì•„ë…¸ ì—°ì£¼ì ë“± ë‹¤ì–‘í•œ ì‚¬ë¡€ ë¶„ì„ì„ í†µí•´ ì—°ìŠµì˜ ë¬¼ë¦¬ì  ì–‘ë³´ë‹¤ ì¤‘ìš”í•œ ê²ƒì€ ì§ˆì ì¸ ì¸¡ë©´ì„ì„ ê°•ì¡°í•œë‹¤. ì ì ˆí•œ \n",
      "íœ´ì‹ ì†ì—ì„œ ë°°ìš´ ê²ƒì„ ì¬ì¡°í•©í•˜ê³ , ëª°ì… ìƒíƒœì—ì„œ ì—°ìŠµí•  ë•Œ ë¹„ë¡œì†Œ 'ìµœê³ 'ë¼ëŠ” ëª©í‘œì— ë„ë‹¬í•  ìˆ˜ ìˆëŠ” ê²ƒì´ë‹¤. ë²Œì¨ 2025ë…„ì´ 100ì¼ ë„˜ê²Œ í˜ë €ë‹¤. ì™„ì—°í•œ ë´„ì„ ë§ì´í•˜ì—¬ ìƒˆë¡œ\n",
      "ìš´ ê¸°ìˆ ì„ ë°°ìš°ê³  ì‹¶ê±°ë‚˜, ê·¸ë™ì•ˆ ë…¸ë ¥ì— ë¹„í•´ ì‹¤ë ¥ì´ ëŠ˜ì§€ ì•ŠëŠ”ë‹¤ê³  ëŠê»´ì™”ë‹¤ë©´, ì´ ì±…ì„ ê¸¸ì¡ì´ ì‚¼ì•„ â€˜ì œëŒ€ë¡œ ì—°ìŠµí•˜ëŠ” ë²•â€™ì„ ë°°ì›Œë³´ë©´ ì–´ë–¨ê¹Œ?\n",
      "\n",
      "table_of_contents:\n",
      "    ì„œë¡  : ì‘ì€ ì¡°ê°ë“¤ì„ ì¬ì¡°í•©í•˜ëŠ” ì¸ê°„ = 7 01ì¥ 'ì œëŒ€ë¡œ' ì—°ìŠµí•˜ê¸° = 17 02ì¥ ëŒ„ ê³„íšê³¼ ì„±ì¸ê¸° ì´í›„ì˜ ìˆ™ë‹¬ : ì‚¬ë¡€ì—°êµ¬ 1 = 41 03ì¥ ì¸ê°„ì˜ ì‚¶ê³¼ ì°½ë°œì„± = 53\n",
      " 04ì¥ ì°½ë°œì  ê¸°ëŠ¥ìœ¼ë¡œì„œì˜ í…Œë‹ˆìŠ¤ ì„œë¸Œ : ì‚¬ë¡€ì—°êµ¬ 2 = 77 05ì¥ ì•„ë™ê¸°, ì²­ì†Œë…„ê¸°ì˜ ë°œë‹¬ ê³¼ì • = 95 06ì¥ í†° ë°”ì´ì–´ì™€ ì‘ì€ ê³µ ìš”ë²• : ì‚¬ë¡€ì—°êµ¬ 3 = 113 07ì¥\n",
      " ì½ê³  ì¸ì‹í•œë‹¤ëŠ” ê²ƒ, ê·¸ ê°€ëŠ¥ì„± = 129 08ì¥ êµ¬ë‹¬ê³¼ ë‰´ì„¬ì˜ ê°ê°ìš´ë™ì  í•´ê²°ì±… : ì‚¬ë¡€ì—°êµ¬ 4 = 157 09ì¥ ì„±ì¸ê¸° ì´í›„ ì–¸ì–´ ìŠµë“ì˜ ê³ í–‰ê¸¸ = 167 10ì¥ ë°”í‹°ì™€ í…Œë‹ˆ\n",
      "ìŠ¤, ê·¸ë¦¬ê³  í¬ë¦¬ì¼“ : ì‚¬ë¡€ì—°êµ¬ 5 = 197 11ì¥ ìœ ì „ìëŠ” í˜¼ìì„œ ì¼í•˜ì§€ ì•ŠëŠ”ë‹¤ = 213 12ì¥ ì¼ë€ì„±ìŒë‘¥ì´ëŠ” ê²°ì½” ë˜‘ê°™ì§€ ì•Šë‹¤ : ì‚¬ë¡€ì—°êµ¬ 6 = 245 13ì¥ ìš°ë¦¬ ì•ˆì˜ \n",
      "ë‘ ìì•„ = 255 14ì¥ 'ê³ ë ¹' ìš´ë™ì„ ìˆ˜ì™€ í™˜ê²½ì˜ ë³€í™” : ì‚¬ë¡€ì—°êµ¬ 7 = 277 15ì¥ ì§„í™”ì™€ í˜ëª…, ê·¸ë¦¬ê³  ìˆ™ë‹¬ = 291 16ì¥ ëˆ ë©”ëª¨ì˜ ê°€ë¥´ì¹¨, ì°½ë°œê³¼ í–¥ìƒ : ì‚¬ë¡€ì—°\n",
      "êµ¬ 8 = 307 ê²°ë¡  : ìˆ™ë‹¬ì˜ ë‹¤ì„¯ ê°€ì§€ ì›ì¹™ = 317 ì°¸ê³  ë¬¸í—Œ = 331 ë„íŒ ì¶œì²˜ = 344 ì°¾ì•„ë³´ê¸° = 345\n",
      "\n",
      "publish_year:\n",
      "    2024\n",
      "\n",
      "recommend_year:\n",
      "    2025\n",
      "\n",
      "recommend_month:\n",
      "    4\n",
      "\n",
      "==================================================\n",
      "ğŸ“š ì „ì²´ ë„ì„œ ìˆ˜: 1388ê¶Œ\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON ë°ì´í„° ë¡œë“œ\n",
    "with open('./data/library_books.json', 'r', encoding='utf-8') as f:\n",
    "    books = json.load(f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“š ë°ì´í„° êµ¬ì¡°\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nğŸ“ ë°ì´í„° í‚¤ ëª©ë¡:\")\n",
    "print(\", \".join(list(books[0].keys())))\n",
    "\n",
    "print(\"\\nğŸ“ ì²« ë²ˆì§¸ ë„ì„œ ìƒì„¸ ì •ë³´:\")\n",
    "for key, value in books[0].items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì¤„ë°”ê¿ˆí•˜ì—¬ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\n",
    "    if len(str(value)) > 100:\n",
    "        # 100ìë§ˆë‹¤ ì¤„ë°”ê¿ˆ\n",
    "        formatted_value = '\\n'.join([str(value)[i:i+100] for i in range(0, len(str(value)), 100)])\n",
    "        print(f\"    {formatted_value}\")\n",
    "    else:\n",
    "        print(f\"    {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"ğŸ“š ì „ì²´ ë„ì„œ ìˆ˜: {len(books)}ê¶Œ\")\n",
    "print(\"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "category ì •ë³´ë¥¼ í™•ì¸í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“š ì´ ë¶„ë¥˜ ìˆ˜: 6ê°œ\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7dd4d th {\n",
       "  text-align: center;\n",
       "  background-color: #f0f0f0;\n",
       "}\n",
       "#T_7dd4d td {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_7dd4d_row0_col0, #T_7dd4d_row0_col1, #T_7dd4d_row0_col2, #T_7dd4d_row1_col0, #T_7dd4d_row1_col1, #T_7dd4d_row1_col2, #T_7dd4d_row2_col0, #T_7dd4d_row2_col1, #T_7dd4d_row2_col2, #T_7dd4d_row3_col0, #T_7dd4d_row3_col1, #T_7dd4d_row3_col2, #T_7dd4d_row4_col0, #T_7dd4d_row4_col1, #T_7dd4d_row4_col2, #T_7dd4d_row5_col0, #T_7dd4d_row5_col1, #T_7dd4d_row5_col2 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7dd4d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7dd4d_level0_col0\" class=\"col_heading level0 col0\" >ë¶„ë¥˜ ì½”ë“œ</th>\n",
       "      <th id=\"T_7dd4d_level0_col1\" class=\"col_heading level0 col1\" >ë¶„ë¥˜ëª…</th>\n",
       "      <th id=\"T_7dd4d_level0_col2\" class=\"col_heading level0 col2\" >ë„ì„œ ìˆ˜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7dd4d_row0_col0\" class=\"data row0 col0\" >6</td>\n",
       "      <td id=\"T_7dd4d_row0_col1\" class=\"data row0 col1\" >ì¸ë¬¸ê³¼í•™</td>\n",
       "      <td id=\"T_7dd4d_row0_col2\" class=\"data row0 col2\" >342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7dd4d_row1_col0\" class=\"data row1 col0\" >5</td>\n",
       "      <td id=\"T_7dd4d_row1_col1\" class=\"data row1 col1\" >ì‚¬íšŒê³¼í•™</td>\n",
       "      <td id=\"T_7dd4d_row1_col2\" class=\"data row1 col2\" >338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_7dd4d_row2_col0\" class=\"data row2 col0\" >4</td>\n",
       "      <td id=\"T_7dd4d_row2_col1\" class=\"data row2 col1\" >ìì—°ê³¼í•™</td>\n",
       "      <td id=\"T_7dd4d_row2_col2\" class=\"data row2 col2\" >319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row3\" class=\"row_heading level0 row3\" >2</th>\n",
       "      <td id=\"T_7dd4d_row3_col0\" class=\"data row3 col0\" >11</td>\n",
       "      <td id=\"T_7dd4d_row3_col1\" class=\"data row3 col1\" >ì–´ë¬¸í•™</td>\n",
       "      <td id=\"T_7dd4d_row3_col2\" class=\"data row3 col2\" >296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7dd4d_row4_col0\" class=\"data row4 col0\" >425</td>\n",
       "      <td id=\"T_7dd4d_row4_col1\" class=\"data row4 col1\" ></td>\n",
       "      <td id=\"T_7dd4d_row4_col2\" class=\"data row4 col2\" >92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7dd4d_row5_col0\" class=\"data row5 col0\" >8</td>\n",
       "      <td id=\"T_7dd4d_row5_col1\" class=\"data row5 col1\" ></td>\n",
       "      <td id=\"T_7dd4d_row5_col2\" class=\"data row5 col2\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x105796e70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# ì¹´í…Œê³ ë¦¬ ì½”ë“œì™€ ì´ë¦„ì„ ë§¤í•‘í•˜ì—¬ ì €ì¥\n",
    "category_map = defaultdict(int)\n",
    "for book in books:\n",
    "    category_key = (book['category_code'], book['category_name'])\n",
    "    category_map[category_key] += 1\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n",
    "df_categories = pd.DataFrame([\n",
    "    {\n",
    "        'ë¶„ë¥˜ ì½”ë“œ': code,\n",
    "        'ë¶„ë¥˜ëª…': name,\n",
    "        'ë„ì„œ ìˆ˜': count\n",
    "    }\n",
    "    for (code, name), count in category_map.items()\n",
    "])\n",
    "\n",
    "# ë„ì„œ ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "df_categories = df_categories.sort_values('ë„ì„œ ìˆ˜', ascending=False)\n",
    "\n",
    "# ìŠ¤íƒ€ì¼ ì ìš©\n",
    "styled_df = df_categories.style\\\n",
    "    .set_properties(**{'text-align': 'center'})\\\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [('text-align', 'center'), ('background-color', '#f0f0f0')]},\n",
    "        {'selector': 'td', 'props': [('text-align', 'center')]},\n",
    "    ])\\\n",
    "    .format({'ë„ì„œ ìˆ˜': '{:,d}'})  # ì²œ ë‹¨ìœ„ êµ¬ë¶„ì ì¶”ê°€\n",
    "\n",
    "# í…Œì´ë¸” ì¶œë ¥\n",
    "print(f\"\\nğŸ“š ì´ ë¶„ë¥˜ ìˆ˜: {len(df_categories)}ê°œ\\n\")\n",
    "display(styled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chuck sizeë¥¼ ì„¤ì •í•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ íŒŒì•…í–ˆë‹¤.\n",
    "\n",
    "ì„ë² ë”©í•  ë°ì´í„°ëŠ” category_name, title, contents, table_of_contentsì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ê° í•„ë“œë³„ í…ìŠ¤íŠ¸ ê¸¸ì´ í†µê³„ ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ì¹´í…Œê³ ë¦¬</th>\n",
       "      <th>ì œëª©</th>\n",
       "      <th>ë‚´ìš©</th>\n",
       "      <th>ëª©ì°¨</th>\n",
       "      <th>ì „ì²´</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>135.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>323.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>861.00</td>\n",
       "      <td>6677.00</td>\n",
       "      <td>7296.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.52</td>\n",
       "      <td>14.16</td>\n",
       "      <td>495.10</td>\n",
       "      <td>884.01</td>\n",
       "      <td>1417.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>4.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>490.00</td>\n",
       "      <td>734.50</td>\n",
       "      <td>1264.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.03</td>\n",
       "      <td>9.65</td>\n",
       "      <td>95.41</td>\n",
       "      <td>740.71</td>\n",
       "      <td>746.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ì¹´í…Œê³ ë¦¬     ì œëª©      ë‚´ìš©       ëª©ì°¨       ì „ì²´\n",
       "min     0.00   1.00  135.00     0.00   323.00\n",
       "max     4.00  75.00  861.00  6677.00  7296.00\n",
       "mean    3.52  14.16  495.10   884.01  1417.79\n",
       "median  4.00  11.00  490.00   734.50  1264.50\n",
       "std     1.03   9.65   95.41   740.71   746.49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´ ë°±ë¶„ìœ„ìˆ˜ ===\n",
      "25ë²ˆì§¸ ë°±ë¶„ìœ„: 881ì\n",
      "50ë²ˆì§¸ ë°±ë¶„ìœ„: 1264ì\n",
      "75ë²ˆì§¸ ë°±ë¶„ìœ„: 1758ì\n",
      "90ë²ˆì§¸ ë°±ë¶„ìœ„: 2343ì\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ê° ë„ì„œë³„ í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°\n",
    "text_lengths = []\n",
    "for book in books:\n",
    "    text = f\"ì¹´í…Œê³ ë¦¬: {book['category_name']}\\nì œëª©: {book['title']}\\në‚´ìš©: {book['contents']}\\nëª©ì°¨: {book['table_of_contents']}\"\n",
    "    length_info = {\n",
    "        'ì¹´í…Œê³ ë¦¬': len(book['category_name']),\n",
    "        'ì œëª©': len(book['title']),\n",
    "        'ë‚´ìš©': len(book['contents']),\n",
    "        'ëª©ì°¨': len(book['table_of_contents']),\n",
    "        'ì „ì²´': len(text)\n",
    "    }\n",
    "    text_lengths.append(length_info)\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df_lengths = pd.DataFrame(text_lengths)\n",
    "\n",
    "# ê¸°ë³¸ í†µê³„ ê³„ì‚°\n",
    "stats = df_lengths.agg(['min', 'max', 'mean', 'median', 'std']).round(2)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n=== ê° í•„ë“œë³„ í…ìŠ¤íŠ¸ ê¸¸ì´ í†µê³„ ===\")\n",
    "display(stats)\n",
    "\n",
    "# ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°\n",
    "percentiles = df_lengths['ì „ì²´'].quantile([0.25, 0.5, 0.75, 0.9])\n",
    "print(\"\\n=== ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´ ë°±ë¶„ìœ„ìˆ˜ ===\")\n",
    "for p, v in percentiles.items():\n",
    "    print(f\"{int(p*100)}ë²ˆì§¸ ë°±ë¶„ìœ„: {int(v)}ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ì‚¬ìš©ì ì •ë³´\n",
    "\n",
    "ì‚¬ìš©ì ì •ë³´ëŠ” ì‚¬ìš©ìê°€ ì½ì€ ì±… ì •ë³´ì™€ ì‚¬ìš©ìì˜ ì±… ì·¨í–¥ ì •ë³´ë¥¼ ì‚¬ìš©í•œë‹¤.\n",
    "\n",
    "#### 1. ì‚¬ìš©ìê°€ ì½ì€ ì±… ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“š ë„ì„œ 1:\n",
      "  title: ì™„ë²½ì´ë¼ëŠ” ì¤‘ë… : ë¶ˆì•ˆí•œ ì™„ë²½ì£¼ì˜ìë¥¼ ìœ„í•œ ì‹¬ë¦¬í•™\n",
      "  author: í† ë¨¸ìŠ¤ ì»¤ëŸ° ì§€ìŒ ;ê¹€ë¬¸ì£¼ ì˜®ê¹€\n",
      "  rating: 4.5\n",
      "  review: ì‹¬ë¦¬í•™ì  ê´€ì ì—ì„œ ìì•„ë¥¼ ì´í•´í•˜ëŠ”ë° ë„ì›€ì´ ë¨\n",
      "  read_date: 2024-01-05\n",
      "  genre: ['ì‹¬ë¦¬í•™', 'ìê¸°ê³„ë°œ']\n",
      "\n",
      "ğŸ“š ë„ì„œ 2:\n",
      "  title: ì¹¨ë¬µì„ ë°°ìš°ëŠ” ì‹œê°„ : ë§ì´ ë„˜ì³ë‚˜ëŠ” ì„¸ìƒ ì†, ë”ìš± ë¹›ì„ ë°œí•˜ëŠ” ì¹¨ë¬µì˜ í’ˆê²©\n",
      "  author: ì½”ë¥´ë„¬ë¦¬ì•„ í† í”„ ì§€ìŒ ;ì¥í˜œê²½ ì˜®ê¹€\n",
      "  rating: 4.0\n",
      "  review: ë”°ëœ»í•œ ìœ„ë¡œê°€ ë˜ëŠ” ì—ì„¸ì´\n",
      "  read_date: 2024-01-15\n",
      "  genre: ['ì—ì„¸ì´', 'ìê¸°ê³„ë°œ']\n",
      "\n",
      "ğŸ“š ë„ì„œ 3:\n",
      "  title: ë‚˜ë‹µê²Œ ì‚°ë‹¤ëŠ” ê²ƒ : ë‚˜ë¥¼ ì°¾ê³ ì í•˜ëŠ” ì´ë“¤ì˜ ì² í•™ìˆ˜ì—…\n",
      "  author: ë°•ì€ë¯¸ ì§€ìŒ\n",
      "  rating: 4.5\n",
      "  review: ì‰½ê²Œ ì½ì„ ìˆ˜ ìˆëŠ” ì² í•™ ì—ì„¸ì´\n",
      "  read_date: 2024-01-25\n",
      "  genre: ['ì² í•™', 'ì—ì„¸ì´']\n",
      "\n",
      "ğŸ“š ë„ì„œ 4:\n",
      "  title: ì¶œê·¼ê¸¸ ì‹¬ë¦¬í•™ : ë‹¨ë‹¨í•˜ê³  ìœ ì—°í•œ ë©˜íƒˆì„ ìœ„í•œ 33ê°€ì§€ ë§ˆìŒì˜ ë²•ì¹™\n",
      "  author: ë°˜ìœ í™” ì§€ìŒ\n",
      "  rating: 3.5\n",
      "  review: ì¼ìƒì ì¸ ì‹¬ë¦¬í•™ ì´ì•¼ê¸°\n",
      "  read_date: 2024-02-05\n",
      "  genre: ['ì‹¬ë¦¬í•™', 'ìê¸°ê³„ë°œ']\n",
      "\n",
      "ğŸ“š ë„ì„œ 5:\n",
      "  title: ë‚´ê°€ ëˆ„êµ¬ì¸ì§€ ì•„ëŠ” ê²ƒì´ ì™œ ì¤‘ìš”í•œê°€\n",
      "  author: í˜í„° ë² ë¥´ ì§€ìŒ ;ì¥í˜œê²½ ì˜®ê¹€\n",
      "  rating: 4.0\n",
      "  review: ìì•„ ì„±ì°°ì— ë„ì›€ì´ ë˜ëŠ” ì±…\n",
      "  read_date: 2024-02-15\n",
      "  genre: ['ì‹¬ë¦¬í•™', 'ì—ì„¸ì´']\n",
      "\n",
      "ğŸ“š ë„ì„œ 6:\n",
      "  title: ìí™”ìƒ ë‚´ ë§ˆìŒì„ ê·¸ë¦¬ë‹¤\n",
      "  author: ê¹€ì„ í˜„ ì§€ìŒ\n",
      "  rating: 3.5\n",
      "  review: ë§ˆìŒì„ ë”°ëœ»í•˜ê²Œ í•´ì£¼ëŠ” ì´ì•¼ê¸°\n",
      "  read_date: 2024-02-25\n",
      "  genre: ['ì—ì„¸ì´']\n",
      "\n",
      "ğŸ“š ë„ì„œ 7:\n",
      "  title: ê°ë³¸ ì—†ìŒ : ì‚¶ì˜ ë‹¤ìŒ í˜ì´ì§€ë¡œ ë„˜ì–´ê°€ê¸° ìœ„í•´ ì“´ ê²ƒë“¤\n",
      "  author: ì•„ë¹„ ëª¨ê±´ ì§€ìŒ ;ì´ìœ ë¦¼ ì˜®ê¹€\n",
      "  rating: 4.0\n",
      "  review: ì¼ìƒì˜ ì†Œì†Œí•œ ìœ„ë¡œ\n",
      "  read_date: 2024-03-05\n",
      "  genre: ['ì—ì„¸ì´', 'ìê¸°ê³„ë°œ']\n",
      "\n",
      "ğŸ“š ë„ì„œ 8:\n",
      "  title: ì„¸ìƒì—ì„œ ê°€ì¥ ê¸´ í–‰ë³µ íƒêµ¬ ë³´ê³ ì„œ\n",
      "  author: ë¡œë²„íŠ¸ ì›”ë”©ê±°,ë§ˆí¬ ìŠì¸  ì§€ìŒ\n",
      "  rating: 3.5\n",
      "  review: í–‰ë³µì— ëŒ€í•œ ì‹¬ë¦¬í•™ì  íƒêµ¬\n",
      "  read_date: 2024-03-15\n",
      "  genre: ['ì‹¬ë¦¬í•™', 'ìê¸°ê³„ë°œ']\n",
      "\n",
      "ğŸ“š ë„ì„œ 9:\n",
      "  title: (ì‡¼íœí•˜ìš°ì–´ì˜) ê³ ë…í•œ í–‰ë³µ\n",
      "  author: ì•„ë¥´íˆ¬ì–´ ì‡¼íœí•˜ìš°ì–´ ì§€ìŒ\n",
      "  rating: 3.0\n",
      "  review: ì² í•™ì  ê´€ì ì˜ ì‚¶ì˜ ì´ì•¼ê¸°\n",
      "  read_date: 2024-03-25\n",
      "  genre: ['ì² í•™', 'ì—ì„¸ì´']\n",
      "\n",
      "ğŸ“š ë„ì„œ 10:\n",
      "  title: ë‚˜ì˜ ë¬¸í•™ ë‹µì‚¬ ì¼ì§€ : ë°°ì›€ì„ ì°¾ì•„ ë– ë‚œ êµ­ë¬¸í•™ìì˜ ì—¬í–‰\n",
      "  author: ì •ë³‘ì„¤ ì§€ìŒ\n",
      "  rating: 4.0\n",
      "  review: ë”°ëœ»í•œ ê°ì„±ì˜ ì—¬í–‰ ì—ì„¸ì´\n",
      "  read_date: 2024-04-01\n",
      "  genre: ['ì—ì„¸ì´', 'ì—¬í–‰']\n"
     ]
    }
   ],
   "source": [
    "with open('./data/test-case/user_reading_history.json', 'r', encoding='utf-8') as f:\n",
    "    reading_history = json.load(f)\n",
    "\n",
    "for i, book in enumerate(reading_history['read_books'], 1):\n",
    "    print(f\"\\nğŸ“š ë„ì„œ {i}:\")\n",
    "    for key, value in book.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. ì‚¬ìš©ìì˜ ì±… ì·¨í–¥ ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“š ì„ í˜¸ ì¥ë¥´:\n",
      "  - ì‹¬ë¦¬í•™ (ê°€ì¤‘ì¹˜: 0.8)\n",
      "  - ìê¸°ê³„ë°œ (ê°€ì¤‘ì¹˜: 0.7)\n",
      "  - ì—ì„¸ì´ (ê°€ì¤‘ì¹˜: 0.6)\n",
      "\n",
      "ğŸ“– ë…ì„œ ìŠ¤íƒ€ì¼:\n",
      "  - preferred_length: ì¤‘ê°„\n",
      "  - complexity_level: ì‰¬ì›€\n",
      "  - tone: ë”°ëœ»í•¨\n",
      "\n",
      "ğŸ”‘ ê´€ì‹¬ í‚¤ì›Œë“œ:\n",
      "  ë¶ˆì•ˆ, íë§, ìœ„ë¡œ, ì‹¬ë¦¬, ì¼ìƒ\n",
      "\n",
      "â›” ê¸°í”¼ ì£¼ì œ:\n",
      "  ìš°ìš¸, ê³µí¬, ê¸´ì¥ê°\n"
     ]
    }
   ],
   "source": [
    "with open('./data/test-case/user_reading_preferences.json', 'r', encoding='utf-8') as f:\n",
    "    reading_preferences = json.load(f)\n",
    "\n",
    "preferences = reading_preferences['preferences']\n",
    "\n",
    "print(\"\\nğŸ“š ì„ í˜¸ ì¥ë¥´:\")\n",
    "for genre in preferences['genres']:\n",
    "    print(f\"  - {genre['name']} (ê°€ì¤‘ì¹˜: {genre['weight']})\")\n",
    "\n",
    "print(\"\\nğŸ“– ë…ì„œ ìŠ¤íƒ€ì¼:\")\n",
    "for key, value in preferences['reading_style'].items():\n",
    "    print(f\"  - {key}: {value}\")\n",
    "\n",
    "print(\"\\nğŸ”‘ ê´€ì‹¬ í‚¤ì›Œë“œ:\")\n",
    "print(f\"  {', '.join(preferences['keywords'])}\")\n",
    "\n",
    "print(\"\\nâ›” ê¸°í”¼ ì£¼ì œ:\")\n",
    "print(f\"  {', '.join(preferences['avoid_topics'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë²¡í„° DB ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ë””ë°”ì´ìŠ¤: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    device_map = {'': 0}\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    device_map = {'': device}\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    device_map = {'': device}\n",
    "\n",
    "print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„ì„œ ì •ë³´ ë²¡í„° DB ìƒì„± ì™„ë£Œ: 2201ê°œ ë¬¸ì„œ\n",
      "ë…ì„œ ì´ë ¥ ë²¡í„° DB ìƒì„± ì™„ë£Œ: 10ê°œ ë¬¸ì„œ\n",
      "ë…ì„œ ì·¨í–¥ ë²¡í„° DB ìƒì„± ì™„ë£Œ: 1ê°œ ë¬¸ì„œ\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "import json\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': device}\n",
    ")\n",
    "\n",
    "#--------------------- 1. ë„ì„œ ì •ë³´ ë²¡í„° DB ---------------------\n",
    "with open('./data/library_books.json', 'r', encoding='utf-8') as f:\n",
    "    books = json.load(f)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "book_documents = []\n",
    "for book in books:\n",
    "    text = f\"ì¹´í…Œê³ ë¦¬: {book['category_name']}\\nì œëª©: {book['title']}\\në‚´ìš©: {book['contents']}\\nëª©ì°¨: {book['table_of_contents']}\"\n",
    "    \n",
    "    metadata = {\n",
    "        'title': book['title'],\n",
    "        'category': book['category_name'],\n",
    "        'author': book['author'],\n",
    "        'isbn': book['isbn'],\n",
    "        'publish_year': book['publish_year'],\n",
    "    }\n",
    "    \n",
    "    chunks = text_splitter.create_documents(\n",
    "        texts=[text],\n",
    "        metadatas=[metadata]\n",
    "    )\n",
    "    book_documents.extend(chunks)\n",
    "\n",
    "# ë„ì„œ ì •ë³´ ë²¡í„° DB ìƒì„±\n",
    "books_vectorstore = Chroma.from_documents(\n",
    "    documents=book_documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"books_collection\"\n",
    ")\n",
    "\n",
    "print(f\"ë„ì„œ ì •ë³´ ë²¡í„° DB ìƒì„± ì™„ë£Œ: {len(book_documents)}ê°œ ë¬¸ì„œ\")\n",
    "\n",
    "#--------------------- 2. ë…ì„œ ì´ë ¥ ë²¡í„° DB ---------------------\n",
    "with open('./data/test-case/user_reading_history.json', 'r', encoding='utf-8') as f:\n",
    "    reading_history = json.load(f)\n",
    "\n",
    "history_documents = []\n",
    "for book in reading_history['read_books']:\n",
    "    text = f\"ì œëª©: {book['title']}\\nì €ì: {book['author']}\\ní‰ì : {book['rating']}\\në¦¬ë·°: {book['review']}\\nì¥ë¥´: {', '.join(book['genre'])}\\nì½ì€ ë‚ ì§œ: {book['read_date']}\"\n",
    "    \n",
    "    metadata = {\n",
    "        'title': book['title'],\n",
    "        'author': book['author'],\n",
    "        'rating': book['rating'],\n",
    "        'genre_str': ', '.join(book['genre']),\n",
    "        'read_date': book['read_date']\n",
    "    }\n",
    "    \n",
    "    doc = Document(page_content=text, metadata=metadata)\n",
    "    history_documents.append(doc)\n",
    "\n",
    "# ë…ì„œ ì´ë ¥ ë²¡í„° DB ìƒì„±\n",
    "history_vectorstore = Chroma.from_documents(\n",
    "    documents=history_documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"reading_history_collection\"\n",
    ")\n",
    "\n",
    "print(f\"ë…ì„œ ì´ë ¥ ë²¡í„° DB ìƒì„± ì™„ë£Œ: {len(history_documents)}ê°œ ë¬¸ì„œ\")\n",
    "\n",
    "#--------------------- 3. ë…ì„œ ì·¨í–¥ ë²¡í„° DB ---------------------\n",
    "with open('./data/test-case/user_reading_preferences.json', 'r', encoding='utf-8') as f:\n",
    "    reading_preferences = json.load(f)\n",
    "\n",
    "preferences_text = f\"ì„ í˜¸ ì¥ë¥´: {', '.join([f'{g['name']}({g['weight']})' for g in reading_preferences['preferences']['genres']])}\\n\"\n",
    "preferences_text += f\"ë…ì„œ ìŠ¤íƒ€ì¼: ê¸¸ì´({reading_preferences['preferences']['reading_style']['preferred_length']}), \"\n",
    "preferences_text += f\"ë³µì¡ë„({reading_preferences['preferences']['reading_style']['complexity_level']}), \"\n",
    "preferences_text += f\"í†¤({reading_preferences['preferences']['reading_style']['tone']})\\n\"\n",
    "preferences_text += f\"ê´€ì‹¬ í‚¤ì›Œë“œ: {', '.join(reading_preferences['preferences']['keywords'])}\\n\"\n",
    "preferences_text += f\"ê¸°í”¼ ì£¼ì œ: {', '.join(reading_preferences['preferences']['avoid_topics'])}\"\n",
    "\n",
    "preferences_metadata = {\n",
    "    'genres_str': ', '.join([g['name'] for g in reading_preferences['preferences']['genres']]),\n",
    "    'keywords_str': ', '.join(reading_preferences['preferences']['keywords']),\n",
    "    'avoid_topics_str': ', '.join(reading_preferences['preferences']['avoid_topics'])\n",
    "}\n",
    "\n",
    "preferences_doc = Document(page_content=preferences_text, metadata=preferences_metadata)\n",
    "\n",
    "# ë…ì„œ ì·¨í–¥ ë²¡í„° DB ìƒì„± (ë‹¨ì¼ ë¬¸ì„œ)\n",
    "preferences_vectorstore = Chroma.from_documents(\n",
    "    documents=[preferences_doc],\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"reading_preferences_collection\"\n",
    ")\n",
    "\n",
    "print(\"ë…ì„œ ì·¨í–¥ ë²¡í„° DB ìƒì„± ì™„ë£Œ: 1ê°œ ë¬¸ì„œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì¶”ì²œ ëª¨ë¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê³µí†µ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# ê³µí†µ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "BASE_RECOMMENDATION_TEMPLATE = \"\"\"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë…ì„œ ì·¨í–¥ê³¼ ê°ì • ìƒíƒœì— ë§ì¶° ë„ì„œë¥¼ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì í•©í•œ {num_recommendations}ê¶Œì˜ ì±…ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## ì‚¬ìš©ì ì •ë³´\n",
    "- í˜„ì¬ ê°ì • ìƒíƒœ: {user_emotion}\n",
    "- ì›í•˜ëŠ” ê°ì •ì  íš¨ê³¼: {desired_emotional_effect}\n",
    "- ì§ì—…: {occupation}\n",
    "- ë…ì„œ ìƒí™©: {reading_context}\n",
    "- ì„ í˜¸í•˜ëŠ” ì§‘ì¤‘ë„: {focus_level}\n",
    "\n",
    "## ì‚¬ìš©ì ì·¨í–¥ ì •ë³´\n",
    "{preferences}\n",
    "\n",
    "## ì‚¬ìš©ìê°€ ì½ì€ ê´€ë ¨ ì±…ë“¤\n",
    "{reading_history}\n",
    "\n",
    "## í›„ë³´ ë„ì„œ ëª©ë¡\n",
    "{candidate_books}\n",
    "\n",
    "ë‹¤ìŒê³¼ ê°™ì€ ì²™ë„ë¡œ ê° í›„ë³´ ë„ì„œë¥¼ í‰ê°€í•˜ì„¸ìš”:\n",
    "1. ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì • ìƒíƒœì™€ ì›í•˜ëŠ” ê°ì •ì  íš¨ê³¼ì™€ì˜ ì í•©ì„±\n",
    "2. ì‚¬ìš©ìì˜ ì·¨í–¥ê³¼ì˜ ì¼ì¹˜ë„ (ì¥ë¥´, ìŠ¤íƒ€ì¼, ì„ í˜¸ í‚¤ì›Œë“œ)\n",
    "3. ì‚¬ìš©ìì˜ ê¸°í”¼ ì£¼ì œì™€ ê²¹ì¹˜ì§€ ì•ŠëŠ”ì§€ ì—¬ë¶€\n",
    "4. ì‚¬ìš©ìì˜ ë…ì„œ ì´ë ¥ê³¼ì˜ ì—°ê´€ì„±\n",
    "5. ë…ì„œ ìƒí™©ê³¼ ì„ í˜¸í•˜ëŠ” ì§‘ì¤‘ë„ì— ë§ëŠ”ì§€ ì—¬ë¶€\n",
    "6. ì‚¬ìš©ìì˜ ì§ì—…ê³¼ ê´€ë ¨ëœ í†µì°°ì´ë‚˜ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€\n",
    "\n",
    "ìµœì¢… ì¶”ì²œì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”:\n",
    "1. [ì²« ë²ˆì§¸ ì¶”ì²œ ë„ì„œ ì œëª©] - ì €ì\n",
    "   - ì¶”ì²œ ì´ìœ : (ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •ê³¼ ì›í•˜ëŠ” íš¨ê³¼ë¥¼ ê³ ë ¤í•œ êµ¬ì²´ì ì¸ ì´ìœ )\n",
    "   - ì´ ì±…ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì´ìœ : (ê°ì •ì  íš¨ê³¼ë‚˜ ì–»ì„ ìˆ˜ ìˆëŠ” í†µì°° ë“±)\n",
    "\n",
    "2. [ë‘ ë²ˆì§¸ ì¶”ì²œ ë„ì„œ ì œëª©] - ì €ì\n",
    "   - ì¶”ì²œ ì´ìœ : (ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •ê³¼ ì›í•˜ëŠ” íš¨ê³¼ë¥¼ ê³ ë ¤í•œ êµ¬ì²´ì ì¸ ì´ìœ )\n",
    "   - ì´ ì±…ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì´ìœ : (ê°ì •ì  íš¨ê³¼ë‚˜ ì–»ì„ ìˆ˜ ìˆëŠ” í†µì°° ë“±)\n",
    "\n",
    "3. [ì„¸ ë²ˆì§¸ ì¶”ì²œ ë„ì„œ ì œëª©] - ì €ì\n",
    "   - ì¶”ì²œ ì´ìœ : (ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •ê³¼ ì›í•˜ëŠ” íš¨ê³¼ë¥¼ ê³ ë ¤í•œ êµ¬ì²´ì ì¸ ì´ìœ )\n",
    "   - ì´ ì±…ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì´ìœ : (ê°ì •ì  íš¨ê³¼ë‚˜ ì–»ì„ ìˆ˜ ìˆëŠ” í†µì°° ë“±)\n",
    "\"\"\"\n",
    "\n",
    "# ê³µí†µ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "base_prompt_template = ChatPromptTemplate.from_template(BASE_RECOMMENDATION_TEMPLATE)\n",
    "\n",
    "# í¬ë§·íŒ… í•¨ìˆ˜ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€\n",
    "def format_reading_history(reading_history_data):\n",
    "    if not reading_history_data:\n",
    "        return \"ê´€ë ¨ ë…ì„œ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # ë‹¤ë‹¨ê³„ RAG ê²°ê³¼ í¬ë§·íŒ…\n",
    "    if isinstance(reading_history_data, list) and all(isinstance(item, dict) and 'metadata' in item for item in reading_history_data):\n",
    "        return \"\\n\\n\".join([\n",
    "            f\"- ë„ì„œ: {item['metadata'].get('title', 'ì œëª© ì—†ìŒ')}\\n\"\n",
    "            f\"  ì €ì: {item['metadata'].get('author', 'ì €ì ë¯¸ìƒ')}\\n\"\n",
    "            f\"  ì¥ë¥´: {item['metadata'].get('genre_str', 'ì¥ë¥´ ì—†ìŒ')}\\n\"\n",
    "            f\"  í‰ì : {item['metadata'].get('rating', 0)}\\n\"\n",
    "            f\"  ë‚´ìš©: {item['content'][:200]}...\"\n",
    "            for item in reading_history_data\n",
    "        ])\n",
    "    \n",
    "    # ì§ì ‘ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…\n",
    "    elif isinstance(reading_history_data, list) and all(isinstance(item, dict) and 'title' in item for item in reading_history_data):\n",
    "        return \"\\n\".join([\n",
    "            f\"- '{item['title']}' (ì €ì: {item['author']}, ì¥ë¥´: {item['genre']}, í‰ì : {item['rating']})\\n  ë¦¬ë·°: {item['review']}\"\n",
    "            for item in reading_history_data\n",
    "        ])\n",
    "    \n",
    "    # ë‹¤ë¥¸ í˜•ì‹ì˜ ë°ì´í„°\n",
    "    return str(reading_history_data)\n",
    "\n",
    "def format_book_candidates(candidates_data):\n",
    "    if not candidates_data:\n",
    "        return \"ì¶”ì²œí•  ë§Œí•œ í›„ë³´ ë„ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # ë‹¤ë‹¨ê³„ RAG ê²°ê³¼ í¬ë§·íŒ…\n",
    "    if isinstance(candidates_data, list) and all(isinstance(item, dict) and 'metadata' in item for item in candidates_data):\n",
    "        return \"\\n\\n\".join([\n",
    "            f\"{i+1}. ì œëª©: {item['metadata'].get('title', 'ì œëª© ì—†ìŒ')}\\n\"\n",
    "            f\"   ì €ì: {item['metadata'].get('author', 'ì €ì ë¯¸ìƒ')}\\n\"\n",
    "            f\"   ì¹´í…Œê³ ë¦¬: {item['metadata'].get('category', 'ì¹´í…Œê³ ë¦¬ ì—†ìŒ')}\\n\"\n",
    "            f\"   ë‚´ìš©: {item['content'][:300]}...\"\n",
    "            for i, item in enumerate(candidates_data)\n",
    "        ])\n",
    "    \n",
    "    # ì§ì ‘ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…\n",
    "    elif isinstance(candidates_data, list) and all(isinstance(item, dict) and 'index' in item for item in candidates_data):\n",
    "        return \"\\n\".join([\n",
    "            f\"{book['index']}. '{book['title']}' (ì €ì: {book['author']}, ì¹´í…Œê³ ë¦¬: {book['category']})\\n   ë‚´ìš© ìš”ì•½: {book['content'][:200]}...\"\n",
    "            for book in candidates_data\n",
    "        ])\n",
    "    \n",
    "    # ë‹¤ë¥¸ í˜•ì‹ì˜ ë°ì´í„°\n",
    "    return str(candidates_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llm ëª¨ë¸ì„ ì •ì˜í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    max_tokens=512,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "chain = base_prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. RAGì— ê¸°ë°˜í•œ ì¶”ì²œ ë¡œì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_stage_rag_search(user_query, num_candidates, num_history_results):\n",
    "    results = {}\n",
    "    \n",
    "    # 1ë‹¨ê³„: í•­ìƒ ì‚¬ìš©ì ì·¨í–¥ ì •ë³´ ê²€ìƒ‰ (ê°€ì¥ ì¤‘ìš”)\n",
    "    preference_results = preferences_vectorstore.similarity_search_with_score(user_query, k=1)\n",
    "    if preference_results:\n",
    "        results['user_preferences'] = preference_results[0]\n",
    "    \n",
    "    # 2ë‹¨ê³„: ì‚¬ìš©ìì˜ ë…ì„œ ì´ë ¥ì—ì„œ ê´€ë ¨ ë„ì„œ ê²€ìƒ‰\n",
    "    history_results = history_vectorstore.similarity_search_with_score(user_query, k=num_history_results)\n",
    "    if history_results:\n",
    "        results['reading_history'] = history_results\n",
    "    \n",
    "    # 3ë‹¨ê³„: ë…ì„œ ì´ë ¥ê³¼ ì·¨í–¥ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ ê°•í™”ëœ ì¿¼ë¦¬ ìƒì„±\n",
    "    enhanced_query = user_query\n",
    "    \n",
    "    # ì·¨í–¥ ì •ë³´ì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "    if 'user_preferences' in results:\n",
    "        pref_doc = results['user_preferences'][0]\n",
    "        keywords = pref_doc.metadata.get('keywords_str', '')\n",
    "        if keywords:\n",
    "            enhanced_query += f\" í‚¤ì›Œë“œ: {keywords}\"\n",
    "    \n",
    "    # ë…ì„œ ì´ë ¥ì—ì„œ ë†’ì€ í‰ì ì˜ ì¥ë¥´ ì¶”ì¶œ\n",
    "    if 'reading_history' in results:\n",
    "        liked_genres = []\n",
    "        for doc, _ in results['reading_history']:\n",
    "            if doc.metadata.get('rating', 0) >= 4.0:\n",
    "                genres = doc.metadata.get('genre_str', '').split(', ')\n",
    "                liked_genres.extend(genres)\n",
    "        \n",
    "        if liked_genres:\n",
    "            unique_genres = list(set(liked_genres))\n",
    "            enhanced_query += f\" ì„ í˜¸ ì¥ë¥´: {', '.join(unique_genres[:3])}\"\n",
    "    \n",
    "    print(f\"ê°•í™”ëœ ì¿¼ë¦¬: {enhanced_query}\")\n",
    "    \n",
    "    # 4ë‹¨ê³„: ê°•í™”ëœ ì¿¼ë¦¬ë¡œ ë„ì„œ ê²€ìƒ‰\n",
    "    book_results = books_vectorstore.similarity_search_with_score(enhanced_query, k=num_candidates)\n",
    "    results['recommended_books'] = book_results\n",
    "    \n",
    "    # ê²°ê³¼ í¬ë§·íŒ… ë° ë°˜í™˜\n",
    "    formatted_results = []\n",
    "    \n",
    "    # ì‚¬ìš©ì ì·¨í–¥ ì •ë³´\n",
    "    if 'user_preferences' in results:\n",
    "        pref_doc, pref_score = results['user_preferences']\n",
    "        formatted_results.append({\n",
    "            'type': 'user_preferences',\n",
    "            'content': pref_doc.page_content,\n",
    "            'metadata': pref_doc.metadata,\n",
    "            'score': pref_score\n",
    "        })\n",
    "    \n",
    "    # ê´€ë ¨ ë…ì„œ ì´ë ¥\n",
    "    if 'reading_history' in results:\n",
    "        for i, (hist_doc, hist_score) in enumerate(results['reading_history']):\n",
    "            if i < 2:  # ìµœëŒ€ 2ê°œë§Œ í¬í•¨\n",
    "                formatted_results.append({\n",
    "                    'type': 'reading_history',\n",
    "                    'content': hist_doc.page_content,\n",
    "                    'metadata': hist_doc.metadata,\n",
    "                    'score': hist_score\n",
    "                })\n",
    "    \n",
    "    # ì¶”ì²œ ë„ì„œ\n",
    "    recommended_count = 0\n",
    "    for book_doc, book_score in results['recommended_books']:\n",
    "        formatted_results.append({\n",
    "            'type': 'recommended_book',\n",
    "            'content': book_doc.page_content,\n",
    "            'metadata': book_doc.metadata,\n",
    "            'score': book_score\n",
    "        })\n",
    "        \n",
    "        recommended_count += 1\n",
    "        if recommended_count >= num_candidates - 2:  # ì·¨í–¥ê³¼ ì´ë ¥ì„ í¬í•¨í•˜ê³  ë‚¨ì€ ìŠ¬ë¡¯ ì±„ìš°ê¸°\n",
    "            break\n",
    "    \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_stage_recommendation(user_emotion, desired_emotional_effect, occupation, reading_context, focus_level, num_candidates=8, num_history_results=3, num_recommendations=3):\n",
    "    \"\"\"ë‹¤ë‹¨ê³„ RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì— ë„ì„œ ì¶”ì²œì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    # ê°ì •ê³¼ ì›í•˜ëŠ” íš¨ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±\n",
    "    search_query = f\"{user_emotion}ì„ ëŠë¼ëŠ” ì‚¬ëŒì´ {desired_emotional_effect}í•  ìˆ˜ ìˆëŠ” ì±…\"\n",
    "    \n",
    "    # ë‹¤ë‹¨ê³„ RAG ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    rag_results = multi_stage_rag_search(search_query, num_candidates, num_history_results)\n",
    "    \n",
    "    # ê²°ê³¼ë¥¼ íƒ€ì…ë³„ë¡œ ë¶„ë¥˜\n",
    "    user_preferences = None\n",
    "    reading_history = []\n",
    "    book_candidates = []\n",
    "    \n",
    "    for item in rag_results:\n",
    "        if item['type'] == 'user_preferences':\n",
    "            user_preferences = item\n",
    "        elif item['type'] == 'reading_history':\n",
    "            reading_history.append(item)\n",
    "        elif item['type'] == 'recommended_book':\n",
    "            book_candidates.append(item)\n",
    "    \n",
    "    # ì·¨í–¥ ì •ë³´ í¬ë§·íŒ…\n",
    "    preferences_formatted = user_preferences['content'] if user_preferences else \"ì·¨í–¥ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # ë…ì„œ ì´ë ¥ ë° í›„ë³´ ë„ì„œ í¬ë§·íŒ… (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "    history_formatted = format_reading_history(reading_history)\n",
    "    candidates_formatted = format_book_candidates(book_candidates)\n",
    "    \n",
    "    result = chain.invoke({\n",
    "        \"user_emotion\": user_emotion,\n",
    "        \"desired_emotional_effect\": desired_emotional_effect,\n",
    "        \"occupation\": occupation,\n",
    "        \"reading_context\": reading_context,\n",
    "        \"focus_level\": focus_level,\n",
    "        \"preferences\": preferences_formatted,\n",
    "        \"reading_history\": history_formatted,\n",
    "        \"candidate_books\": candidates_formatted,\n",
    "        \"num_recommendations\": num_recommendations\n",
    "    })\n",
    "    \n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Prompt ê¸°ë°˜ì˜ ì¶”ì²œ ë¡œì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì ì·¨í–¥ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì·¨í–¥ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ… (í”„ë¡¬í”„íŠ¸ì— ì§ì ‘ ì‚¬ìš©)\n",
    "preferences_formatted = f\"\"\"\n",
    "## ì‚¬ìš©ì ë…ì„œ ì·¨í–¥ ì •ë³´\n",
    "- ì„ í˜¸ ì¥ë¥´: {', '.join([f\"{g['name']}(ê°€ì¤‘ì¹˜:{g['weight']})\" for g in reading_preferences['preferences']['genres']])}\n",
    "- ì„ í˜¸ ë…ì„œ ìŠ¤íƒ€ì¼: \n",
    "  * ì„ í˜¸ ê¸¸ì´: {reading_preferences['preferences']['reading_style']['preferred_length']}\n",
    "  * ë³µì¡ë„: {reading_preferences['preferences']['reading_style']['complexity_level']}\n",
    "  * ì„ í˜¸ í†¤: {reading_preferences['preferences']['reading_style']['tone']}\n",
    "- ê´€ì‹¬ í‚¤ì›Œë“œ: {', '.join(reading_preferences['preferences']['keywords'])}\n",
    "- ê¸°í”¼ ì£¼ì œ: {', '.join(reading_preferences['preferences']['avoid_topics'])}\n",
    "\"\"\"\n",
    "\n",
    "print(\"ì‚¬ìš©ì ì·¨í–¥ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_vector_recommendation(user_emotion, desired_emotional_effect, occupation, reading_context, focus_level, num_candidates=8, num_history_results=3, num_recommendations=3):\n",
    "    \"\"\"ë²¡í„° DB ì§ì ‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì— ë„ì„œ ì¶”ì²œì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    # ê°ì •ê³¼ ì›í•˜ëŠ” íš¨ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±\n",
    "    search_query = f\"{user_emotion}ì„ ëŠë¼ëŠ” ì‚¬ëŒì´ {desired_emotional_effect}í•  ìˆ˜ ìˆëŠ” ì±…\"\n",
    "    \n",
    "    # 1. ì¿¼ë¦¬ì— ê´€ë ¨ëœ ë„ì„œ ê²€ìƒ‰\n",
    "    book_results = books_vectorstore.similarity_search_with_score(search_query, k=num_candidates)\n",
    "    \n",
    "    # 2. ì‚¬ìš©ìì˜ ë…ì„œ ì´ë ¥ ì¤‘ ê´€ë ¨ ìˆëŠ” ì±… ê²€ìƒ‰\n",
    "    history_results = history_vectorstore.similarity_search_with_score(search_query, k=num_history_results)\n",
    "    \n",
    "    # 3. ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…\n",
    "    candidate_books = []\n",
    "    for i, (doc, score) in enumerate(book_results):\n",
    "        book_info = {\n",
    "            'index': i+1,\n",
    "            'title': doc.metadata.get('title', 'ì œëª© ì—†ìŒ'),\n",
    "            'author': doc.metadata.get('author', 'ì €ì ë¯¸ìƒ'),\n",
    "            'category': doc.metadata.get('category', 'ë¶„ë¥˜ ì—†ìŒ'),\n",
    "            'content': doc.page_content.strip()[:500] + \"...\" if len(doc.page_content) > 500 else doc.page_content.strip(),\n",
    "            'similarity_score': score\n",
    "        }\n",
    "        candidate_books.append(book_info)\n",
    "    \n",
    "    reading_history_formatted = []\n",
    "    for doc, score in history_results:\n",
    "        history_info = {\n",
    "            'title': doc.metadata.get('title', 'ì œëª© ì—†ìŒ'),\n",
    "            'author': doc.metadata.get('author', 'ì €ì ë¯¸ìƒ'),\n",
    "            'genre': doc.metadata.get('genre_str', 'ì¥ë¥´ ì—†ìŒ'),\n",
    "            'rating': doc.metadata.get('rating', 0),\n",
    "            'review': doc.page_content.split('ë¦¬ë·°: ')[1].split('\\n')[0] if 'ë¦¬ë·°: ' in doc.page_content else 'ë¦¬ë·° ì—†ìŒ'\n",
    "        }\n",
    "        reading_history_formatted.append(history_info)\n",
    "    \n",
    "    # ë…ì„œ ì´ë ¥ ë° í›„ë³´ ë„ì„œ í¬ë§·íŒ… (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "    history_formatted = format_reading_history(reading_history_formatted)\n",
    "    candidates_formatted = format_book_candidates(candidate_books)\n",
    "    \n",
    "    result = chain.invoke({\n",
    "        \"user_emotion\": user_emotion,\n",
    "        \"desired_emotional_effect\": desired_emotional_effect,\n",
    "        \"occupation\": occupation,\n",
    "        \"reading_context\": reading_context,\n",
    "        \"focus_level\": focus_level,\n",
    "        \"preferences\": preferences_formatted,  # ì‚¬ìš©ì ì·¨í–¥ ì •ë³´ (ì „ì—­ ë³€ìˆ˜)\n",
    "        \"reading_history\": history_formatted,\n",
    "        \"candidate_books\": candidates_formatted,\n",
    "        \"num_recommendations\": num_recommendations\n",
    "    })\n",
    "    \n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_recommendations(user_emotion, desired_emotional_effect, occupation, reading_context, focus_level, method=\"both\"):\n",
    "    print(f\"í˜„ì¬ ê°ì • ìƒíƒœ: {user_emotion}\")\n",
    "    print(f\"ì›í•˜ëŠ” ê°ì •ì  íš¨ê³¼: {desired_emotional_effect}\")\n",
    "    print(f\"ì§ì—…: {occupation}\")\n",
    "    print(f\"ë…ì„œ ìƒí™©: {reading_context}\")\n",
    "    print(f\"ì„ í˜¸í•˜ëŠ” ì§‘ì¤‘ë„: {focus_level}\")\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    num_candidates = 6\n",
    "    num_history_results = 3\n",
    "    num_recommendations = 3\n",
    "    \n",
    "    if method in [\"multi_stage\", \"both\"]:\n",
    "        print(\"\\në‹¤ë‹¨ê³„ RAG ê¸°ë°˜ ì¶”ì²œ ë„ì„œë¥¼ ì°¾ëŠ” ì¤‘...\\n\")\n",
    "        multi_stage_result = multi_stage_recommendation(\n",
    "            user_emotion=user_emotion,\n",
    "            desired_emotional_effect=desired_emotional_effect,\n",
    "            occupation=occupation,\n",
    "            reading_context=reading_context,\n",
    "            focus_level=focus_level,\n",
    "            num_candidates=num_candidates,\n",
    "            num_history_results=num_history_results,\n",
    "            num_recommendations=num_recommendations\n",
    "        )\n",
    "        results[\"multi_stage\"] = multi_stage_result\n",
    "    \n",
    "    if method in [\"direct\", \"both\"]:\n",
    "        print(\"\\nì§ì ‘ ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ì¶”ì²œ ë„ì„œë¥¼ ì°¾ëŠ” ì¤‘...\\n\")\n",
    "        direct_result = direct_vector_recommendation(\n",
    "            user_emotion=user_emotion,\n",
    "            desired_emotional_effect=desired_emotional_effect,\n",
    "            occupation=occupation,\n",
    "            reading_context=reading_context,\n",
    "            focus_level=focus_level,\n",
    "            num_candidates=num_candidates,\n",
    "            num_history_results=num_history_results,\n",
    "            num_recommendations=num_recommendations\n",
    "        )\n",
    "        results[\"direct\"] = direct_result\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ê°ì • ìƒíƒœ: ë¶ˆì•ˆí•¨\n",
      "ì›í•˜ëŠ” ê°ì •ì  íš¨ê³¼: ìœ„ë¡œì™€ ì•ˆì •ê°\n",
      "ì§ì—…: ì§ì¥ì¸\n",
      "ë…ì„œ ìƒí™©: ì ë“¤ê¸° ì „ ë…ì„œ\n",
      "ì„ í˜¸í•˜ëŠ” ì§‘ì¤‘ë„: ê°€ë³ê²Œ ì½ì„ ìˆ˜ ìˆëŠ” ì±…\n",
      "\n",
      "ë‹¤ë‹¨ê³„ RAG ê¸°ë°˜ ì¶”ì²œ ë„ì„œë¥¼ ì°¾ëŠ” ì¤‘...\n",
      "\n",
      "ê°•í™”ëœ ì¿¼ë¦¬: ë¶ˆì•ˆí•¨ì„ ëŠë¼ëŠ” ì‚¬ëŒì´ ìœ„ë¡œì™€ ì•ˆì •ê°í•  ìˆ˜ ìˆëŠ” ì±… í‚¤ì›Œë“œ: ë¶ˆì•ˆ, íë§, ìœ„ë¡œ, ì‹¬ë¦¬, ì¼ìƒ ì„ í˜¸ ì¥ë¥´: ì—ì„¸ì´, ì—¬í–‰\n",
      "\n",
      "ì§ì ‘ ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ì¶”ì²œ ë„ì„œë¥¼ ì°¾ëŠ” ì¤‘...\n",
      "\n",
      "\n",
      "=== ë‹¤ë‹¨ê³„ RAG ê¸°ë°˜ ë„ì„œ ì¶”ì²œ ê²°ê³¼ ===\n",
      "\n",
      "1. **[ë¶ˆì•ˆí•´ ë³´ì—¬ì„œ ë¶ˆì•ˆí•œ ë‹¹ì‹ ì—ê²Œ] - í•œì°½ìš±**\n",
      "   - ì¶”ì²œ ì´ìœ : ì´ ì±…ì€ ë¶ˆì•ˆí•œ ì²­ì¶˜ë“¤ì„ ìœ„ë¡œí•˜ê³ , ê·¸ë“¤ì˜ ê°ì •ì„ ì´í•´í•´ ì£¼ëŠ” ì—í”¼ì†Œë“œë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ í˜„ì¬ ëŠë¼ê³  ìˆëŠ” ë¶ˆì•ˆê°ì— ê³µê°í•˜ë©°, ì´ë¥¼ ëœì–´ì¤„ ìˆ˜ ìˆëŠ” ë”°ëœ»í•œ ë©”ì‹œì§€ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. \n",
      "   - ì´ ì±…ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì´ìœ : ë‹¤ì–‘í•œ ì‚¬ë¡€ë¥¼ í†µí•´ ë¶ˆì•ˆì˜ ì›ì¸ê³¼ ê·¸ì— ëŒ€í•œ ëŒ€ì²˜ ë°©ì•ˆì„ ì œì‹œí•˜ë¯€ë¡œ, ì‚¬ìš©ìê°€ ëŠë¼ëŠ” ê°ì •ì— ëŒ€í•œ ì´í•´ì™€ ìœ„ë¡œë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì¼ìƒì—ì„œì˜ ë¶ˆì•ˆê°ì„ í•´ì†Œí•˜ëŠ” ë° í•„ìš”í•œ í†µì°°ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **[ì ê¹ ë¨¸ë¦¬ ì¢€ ì‹íˆê³  ì˜¤ê² ìŠµë‹ˆë‹¤] - ìœ¤ëŒ€í˜„**\n",
      "   - ì¶”ì²œ ì´ìœ : ì´ ì±…ì€ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ì™€ ë§ˆìŒì˜ ì•ˆì •ì„ ìœ„í•œ ì‹¬ë¦¬ ì²˜ë°©ì „ì„ ì œê³µí•˜ë©°, ì§ì¥ì¸ìœ¼ë¡œì„œì˜ ì¼ìƒì—ì„œ ëŠë¼ëŠ” ë¶ˆì•ˆê°ì„ ì´í•´í•˜ê³  ê·¹ë³µí•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "   - ì´ ì±…ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì´ìœ : ì €ìê°€ ì œì‹œí•˜ëŠ” ë‹¤ì–‘í•œ íŒê³¼ ì¡°ì–¸ì€ ì§ì¥ ìƒí™œì—ì„œì˜ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì¤„ì´ê³  ìì¡´ê°ì„ ë†’ì´ëŠ” ë° ìœ ìš©í•˜ë©°, ê°€ë²¼ìš´ ë¬¸ì²´ë¡œ ì‰½ê²Œ ì½ì„ ìˆ˜ ìˆì–´ ì ë“¤ê¸° ì „ ë…ì„œì— ì í•©í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **[ìí™”ìƒ ë‚´ ë§ˆìŒì„ ê·¸ë¦¬ë‹¤] - ê¹€ì„ í˜„**\n",
      "   - ì¶”ì²œ ì´ìœ : ì‚¬ìš©ìê°€ ì´ë¯¸ ì½ê³  ê¸ì •ì ì¸ í‰ê°€ë¥¼ í•œ ì±…ìœ¼ë¡œ, ë”°ëœ»í•œ ì´ì•¼ê¸°ë¡œ ë§ˆìŒì„ ìœ„ë¡œí•´ ì¤„ ìˆ˜ ìˆëŠ” ë‚´ìš©ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì±…ì€ ê°ì •ì˜ ê¹Šì´ë¥¼ ì´í•´í•˜ê³  ì¼ìƒì—ì„œ ëŠë¼ëŠ” ë¶ˆì•ˆì„ í•´ì†Œí•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ê²ƒì…ë‹ˆë‹¤.\n",
      "   - ì´ ì±…ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì´ìœ : ì´ë¯¸ ê¸ì •ì ì¸ ê²½í—˜ì´ ìˆëŠ” ì±…ì´ë¯€ë¡œ, ë¹„ìŠ·í•œ ëŠë‚Œì˜ ê°ì •ì  ì•ˆì •ê³¼ ìœ„ë¡œë¥¼ ì œê³µí•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ë˜í•œ, ì‹¬ë¦¬í•™ì ì¸ ê´€ì ì—ì„œ ì¼ìƒì ì¸ ë¬¸ì œë¥¼ ë‹¤ë£¨ê³  ìˆì–´ ì‚¬ìš©ìì˜ ê´€ì‹¬ê³¼ ì˜ ë§ì•„ë–¨ì–´ì§‘ë‹ˆë‹¤.\n",
      "\n",
      "=== ì§ì ‘ ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë„ì„œ ì¶”ì²œ ê²°ê³¼ ===\n",
      "\n",
      "ì‚¬ìš©ìì˜ ë…ì„œ ì·¨í–¥ê³¼ ê°ì • ìƒíƒœë¥¼ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ë„ì„œë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "1. **[ì •ì¡°ì²˜ëŸ¼ ì†Œí†µí•˜ë¼] - ì €ì: ì •ì°½ê¶Œ**\n",
      "   - ì¶”ì²œ ì´ìœ : ì´ ì±…ì€ ì†Œí†µì˜ ì¤‘ìš”ì„±ê³¼ ë”°ëœ»í•œ ì¸ê°„ê´€ê³„ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. í˜„ì¬ ë¶ˆì•ˆí•œ ê°ì •ì„ ê°€ì§„ ì‚¬ìš©ìì—ê²Œ ì†Œí†µê³¼ ì´í•´ë¥¼ í†µí•œ ìœ„ë¡œì™€ ì•ˆì •ê°ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "   - ì´ ì±…ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì´ìœ : ì†Œí†µì˜ ê¸°ìˆ ì„ ë°°ìš°ê³ , ì£¼ë³€ ì‚¬ëŒë“¤ê³¼ì˜ ê´€ê³„ë¥¼ ê°œì„ í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ìì—ê²Œ ì‹¬ë¦¬ì  ì•ˆì •ì„ ì£¼ê³ , ë¶ˆì•ˆê°ì„ ëœì–´ì£¼ëŠ” ë° ê¸°ì—¬í•  ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "2. **[ë³´ê³  ìƒê°í•˜ê³  ëŠë¼ëŠ” ìš°ë¦¬ ëª…ìŠ¹ê¸°í–‰] - ì €ì: ê¹€í•™ë²”**\n",
      "   - ì¶”ì²œ ì´ìœ : ì´ ì±…ì€ í•œêµ­ì˜ ì•„ë¦„ë‹¤ìš´ ëª…ìŠ¹ì§€ë¥¼ ì†Œê°œí•˜ë©°, ì¼ìƒì—ì„œ ë²—ì–´ë‚˜ ìì—°ì˜ ì•„ë¦„ë‹¤ì›€ì„ ëŠë¼ê²Œ í•´ì¤ë‹ˆë‹¤. ë¶ˆì•ˆí•œ ë§ˆìŒì„ ì•ˆì •ì‹œí‚¤ê³  íë§ì˜ íš¨ê³¼ë¥¼ ì¤„ ìˆ˜ ìˆëŠ” ë”°ëœ»í•œ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
      "   - ì´ ì±…ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì´ìœ : ìì—°ê³¼ ë¬¸í™”ì— ëŒ€í•œ ì—ì„¸ì´ëŠ” ë…ì„œ ì¤‘ì— í¸ì•ˆí•¨ì„ ì œê³µí•˜ë©°, ì‚¬ìš©ìê°€ ì ë“¤ê¸° ì „ ì½ê¸°ì— ì í•©í•©ë‹ˆë‹¤. ì¼ìƒì—ì„œ ëŠë¼ëŠ” ë¶ˆì•ˆê°ì„ ìŠê³  ë§ˆìŒì˜ ì—¬ìœ ë¥¼ ì°¾ëŠ” ë° ë„ì›€ì„ ì¤„ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "3. **[ìí™”ìƒ ë‚´ ë§ˆìŒì„ ê·¸ë¦¬ë‹¤] - ì €ì: ê¹€ì„ í˜„**\n",
      "   - ì¶”ì²œ ì´ìœ : ì‚¬ìš©ìê°€ ì´ë¯¸ ì½ê³  ê¸ì •ì ì¸ ë°˜ì‘ì„ ë³´ì¸ ì±…ìœ¼ë¡œ, ë§ˆìŒì„ ë”°ëœ»í•˜ê²Œ í•´ì£¼ëŠ” ì´ì•¼ê¸°ë¡œ ë¶ˆì•ˆí•¨ì„ ëœì–´ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°ì •ì ìœ¼ë¡œ ì¹œìˆ™í•œ ë‚´ìš©ì´ ì‚¬ìš©ìì—ê²Œ ì•ˆì •ê°ì„ ì¤„ ê²ƒì…ë‹ˆë‹¤.\n",
      "   - ì´ ì±…ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì´ìœ : ì‚¬ìš©ìì—ê²Œ ìœ„ë¡œì™€ ê³µê°ì„ ì œê³µí•˜ë©°, ë…ì„œ í›„ í¸ì•ˆí•œ ë§ˆìŒê°€ì§ì„ ê°–ê²Œ í•´ ì¤„ ê²ƒì…ë‹ˆë‹¤. ë˜í•œ ì ë“¤ê¸° ì „ ì½ê¸°ì— ì í•©í•˜ì—¬ ë…ì„œ ìƒí™©ê³¼ ì˜ ë§ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ ë„ì„œë“¤ì€ ì‚¬ìš©ìì˜ ë¶ˆì•ˆí•œ ê°ì • ìƒíƒœë¥¼ ìœ„ë¡œí•˜ê³ , ì•ˆì •ê°ì„ ì¤„ ìˆ˜ ìˆëŠ” ë‚´ìš©ì„ ë‹´ê³  ìˆì–´ ì¶”ì²œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ (README.mdì˜ TestCase1ì— ë§ê²Œ ìˆ˜ì •)\n",
    "test_results = get_book_recommendations(\n",
    "    user_emotion=\"ë¶ˆì•ˆí•¨\",                      # ì§ˆë¬¸ 1 ì‘ë‹µ\n",
    "    desired_emotional_effect=\"ìœ„ë¡œì™€ ì•ˆì •ê°\",     # ì§ˆë¬¸ 2 ì‘ë‹µ\n",
    "    occupation=\"ì§ì¥ì¸\",                       # ì§ˆë¬¸ 3 ì‘ë‹µ\n",
    "    reading_context=\"ì ë“¤ê¸° ì „ ë…ì„œ\",            # ì§ˆë¬¸ 4 ì‘ë‹µ\n",
    "    focus_level=\"ê°€ë³ê²Œ ì½ì„ ìˆ˜ ìˆëŠ” ì±…\",         # ì§ˆë¬¸ 5 ì‘ë‹µ\n",
    "    method=\"both\"  # ë‘ ë°©ì‹ ëª¨ë‘ ì‚¬ìš©\n",
    ")\n",
    "\n",
    "print(\"\\n=== ë‹¤ë‹¨ê³„ RAG ê¸°ë°˜ ë„ì„œ ì¶”ì²œ ê²°ê³¼ ===\\n\")\n",
    "print(test_results.get(\"multi_stage\", \"ê²°ê³¼ ì—†ìŒ\"))\n",
    "\n",
    "print(\"\\n=== ì§ì ‘ ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë„ì„œ ì¶”ì²œ ê²°ê³¼ ===\\n\")\n",
    "print(test_results.get(\"direct\", \"ê²°ê³¼ ì—†ìŒ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
