{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.3.24)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (1.75.0)\n",
      "Requirement already satisfied: chromadb in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.6.3)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (2.6.0)\n",
      "Collecting langchain_huggingface\n",
      "  Using cached langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (0.3.55)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (0.3.32)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.115.12)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (3.25.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.21.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (3.10.16)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_huggingface) (0.30.2)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_huggingface) (4.1.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain_huggingface) (4.51.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: packaging>=19.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.46.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.39.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.15.2)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.2.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Using cached langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: langchain_huggingface\n",
      "Successfully installed langchain_huggingface-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv pandas langchain openai chromadb torch langchain_huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG로 사용할 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 도서 정보 데이터\n",
    "\n",
    "데이터는 공공API에서 제공하는 [국립중앙도서관 사서추천도서목록](https://www.nl.go.kr/NL/contents/N31101030900.do)을 사용한다.\n",
    "\n",
    "xml 데이터를 json 데이터로 변환하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "📚 데이터 구조\n",
      "==================================================\n",
      "\n",
      "📍 데이터 키 목록:\n",
      "category_code, category_name, title, author, publisher, isbn, contents, table_of_contents, publish_year, recommend_year, recommend_month\n",
      "\n",
      "📍 첫 번째 도서 상세 정보:\n",
      "\n",
      "category_code:\n",
      "    6\n",
      "\n",
      "category_name:\n",
      "    인문과학\n",
      "\n",
      "title:\n",
      "    제대로 연습하는 법 : 어학부터 스포츠까지, 인지심리학이 제시하는 배움의 기술\n",
      "\n",
      "author:\n",
      "    아투로 E. 허낸데즈 지음 ;방진이 옮김\n",
      "\n",
      "publisher:\n",
      "    북트리거 지학사\n",
      "\n",
      "isbn:\n",
      "    9791193378335\n",
      "\n",
      "contents:\n",
      "    한때 유행했던 일만 시간의 법칙을 기억하는가? 어떤 분야에서 전문가가 되려면 최소한 일만 시간의 훈련이 필요하다는 개념이다. 하지만 단순히 연습의 양이 많다고 해서 모두가 전문가가\n",
      " 되는 것은 아니다. 이 책은 심리학자이자 다중언어 구사자, 테니스 선수로도 활약했던 저자가 학습과 훈련, 그리고 기량 향상의 상관관계를 연구한 결과를 담고 있다. 장 피아제, 노\n",
      "엄 촘스키, 그리고 일만 시간의 법칙을 제창한 심리학자 안데르스 에릭손 등 대가들의 이론 및 최신 연구 결과를 바탕으로, 뇌과학과 인지심리학적 관점에서 '제대로 연습하는 법'을 탐\n",
      "구한다. 아마추어 스포츠 선수, 유명 체스 선수, 다중언어 구사자, 피아노 연주자 등 다양한 사례 분석을 통해 연습의 물리적 양보다 중요한 것은 질적인 측면임을 강조한다. 적절한 \n",
      "휴식 속에서 배운 것을 재조합하고, 몰입 상태에서 연습할 때 비로소 '최고'라는 목표에 도달할 수 있는 것이다. 벌써 2025년이 100일 넘게 흘렀다. 완연한 봄을 맞이하여 새로\n",
      "운 기술을 배우고 싶거나, 그동안 노력에 비해 실력이 늘지 않는다고 느껴왔다면, 이 책을 길잡이 삼아 ‘제대로 연습하는 법’을 배워보면 어떨까?\n",
      "\n",
      "table_of_contents:\n",
      "    서론 : 작은 조각들을 재조합하는 인간 = 7 01장 '제대로' 연습하기 = 17 02장 댄 계획과 성인기 이후의 숙달 : 사례연구 1 = 41 03장 인간의 삶과 창발성 = 53\n",
      " 04장 창발적 기능으로서의 테니스 서브 : 사례연구 2 = 77 05장 아동기, 청소년기의 발달 과정 = 95 06장 톰 바이어와 작은 공 요법 : 사례연구 3 = 113 07장\n",
      " 읽고 인식한다는 것, 그 가능성 = 129 08장 구달과 뉴섬의 감각운동적 해결책 : 사례연구 4 = 157 09장 성인기 이후 언어 습득의 고행길 = 167 10장 바티와 테니\n",
      "스, 그리고 크리켓 : 사례연구 5 = 197 11장 유전자는 혼자서 일하지 않는다 = 213 12장 일란성쌍둥이는 결코 똑같지 않다 : 사례연구 6 = 245 13장 우리 안의 \n",
      "두 자아 = 255 14장 '고령' 운동선수와 환경의 변화 : 사례연구 7 = 277 15장 진화와 혁명, 그리고 숙달 = 291 16장 돈 메모의 가르침, 창발과 향상 : 사례연\n",
      "구 8 = 307 결론 : 숙달의 다섯 가지 원칙 = 317 참고 문헌 = 331 도판 출처 = 344 찾아보기 = 345\n",
      "\n",
      "publish_year:\n",
      "    2024\n",
      "\n",
      "recommend_year:\n",
      "    2025\n",
      "\n",
      "recommend_month:\n",
      "    4\n",
      "\n",
      "==================================================\n",
      "📚 전체 도서 수: 1388권\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON 데이터 로드\n",
    "with open('./data/library_books.json', 'r', encoding='utf-8') as f:\n",
    "    books = json.load(f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📚 데이터 구조\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\n📍 데이터 키 목록:\")\n",
    "print(\", \".join(list(books[0].keys())))\n",
    "\n",
    "print(\"\\n📍 첫 번째 도서 상세 정보:\")\n",
    "for key, value in books[0].items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    # 긴 텍스트는 줄바꿈하여 보기 좋게 출력\n",
    "    if len(str(value)) > 100:\n",
    "        # 100자마다 줄바꿈\n",
    "        formatted_value = '\\n'.join([str(value)[i:i+100] for i in range(0, len(str(value)), 100)])\n",
    "        print(f\"    {formatted_value}\")\n",
    "    else:\n",
    "        print(f\"    {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"📚 전체 도서 수: {len(books)}권\")\n",
    "print(\"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "category 정보를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 총 분류 수: 6개\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7dd4d th {\n",
       "  text-align: center;\n",
       "  background-color: #f0f0f0;\n",
       "}\n",
       "#T_7dd4d td {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_7dd4d_row0_col0, #T_7dd4d_row0_col1, #T_7dd4d_row0_col2, #T_7dd4d_row1_col0, #T_7dd4d_row1_col1, #T_7dd4d_row1_col2, #T_7dd4d_row2_col0, #T_7dd4d_row2_col1, #T_7dd4d_row2_col2, #T_7dd4d_row3_col0, #T_7dd4d_row3_col1, #T_7dd4d_row3_col2, #T_7dd4d_row4_col0, #T_7dd4d_row4_col1, #T_7dd4d_row4_col2, #T_7dd4d_row5_col0, #T_7dd4d_row5_col1, #T_7dd4d_row5_col2 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7dd4d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7dd4d_level0_col0\" class=\"col_heading level0 col0\" >분류 코드</th>\n",
       "      <th id=\"T_7dd4d_level0_col1\" class=\"col_heading level0 col1\" >분류명</th>\n",
       "      <th id=\"T_7dd4d_level0_col2\" class=\"col_heading level0 col2\" >도서 수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7dd4d_row0_col0\" class=\"data row0 col0\" >6</td>\n",
       "      <td id=\"T_7dd4d_row0_col1\" class=\"data row0 col1\" >인문과학</td>\n",
       "      <td id=\"T_7dd4d_row0_col2\" class=\"data row0 col2\" >342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7dd4d_row1_col0\" class=\"data row1 col0\" >5</td>\n",
       "      <td id=\"T_7dd4d_row1_col1\" class=\"data row1 col1\" >사회과학</td>\n",
       "      <td id=\"T_7dd4d_row1_col2\" class=\"data row1 col2\" >338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_7dd4d_row2_col0\" class=\"data row2 col0\" >4</td>\n",
       "      <td id=\"T_7dd4d_row2_col1\" class=\"data row2 col1\" >자연과학</td>\n",
       "      <td id=\"T_7dd4d_row2_col2\" class=\"data row2 col2\" >319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row3\" class=\"row_heading level0 row3\" >2</th>\n",
       "      <td id=\"T_7dd4d_row3_col0\" class=\"data row3 col0\" >11</td>\n",
       "      <td id=\"T_7dd4d_row3_col1\" class=\"data row3 col1\" >어문학</td>\n",
       "      <td id=\"T_7dd4d_row3_col2\" class=\"data row3 col2\" >296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7dd4d_row4_col0\" class=\"data row4 col0\" >425</td>\n",
       "      <td id=\"T_7dd4d_row4_col1\" class=\"data row4 col1\" ></td>\n",
       "      <td id=\"T_7dd4d_row4_col2\" class=\"data row4 col2\" >92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dd4d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7dd4d_row5_col0\" class=\"data row5 col0\" >8</td>\n",
       "      <td id=\"T_7dd4d_row5_col1\" class=\"data row5 col1\" ></td>\n",
       "      <td id=\"T_7dd4d_row5_col2\" class=\"data row5 col2\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x105796e70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 카테고리 코드와 이름을 매핑하여 저장\n",
    "category_map = defaultdict(int)\n",
    "for book in books:\n",
    "    category_key = (book['category_code'], book['category_name'])\n",
    "    category_map[category_key] += 1\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "df_categories = pd.DataFrame([\n",
    "    {\n",
    "        '분류 코드': code,\n",
    "        '분류명': name,\n",
    "        '도서 수': count\n",
    "    }\n",
    "    for (code, name), count in category_map.items()\n",
    "])\n",
    "\n",
    "# 도서 수를 기준으로 내림차순 정렬\n",
    "df_categories = df_categories.sort_values('도서 수', ascending=False)\n",
    "\n",
    "# 스타일 적용\n",
    "styled_df = df_categories.style\\\n",
    "    .set_properties(**{'text-align': 'center'})\\\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [('text-align', 'center'), ('background-color', '#f0f0f0')]},\n",
    "        {'selector': 'td', 'props': [('text-align', 'center')]},\n",
    "    ])\\\n",
    "    .format({'도서 수': '{:,d}'})  # 천 단위 구분자 추가\n",
    "\n",
    "# 테이블 출력\n",
    "print(f\"\\n📚 총 분류 수: {len(df_categories)}개\\n\")\n",
    "display(styled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chuck size를 설정하기 위해 텍스트 길이를 파악했다.\n",
    "\n",
    "임베딩할 데이터는 category_name, title, contents, table_of_contents이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 각 필드별 텍스트 길이 통계 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>카테고리</th>\n",
       "      <th>제목</th>\n",
       "      <th>내용</th>\n",
       "      <th>목차</th>\n",
       "      <th>전체</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>135.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>323.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>861.00</td>\n",
       "      <td>6677.00</td>\n",
       "      <td>7296.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.52</td>\n",
       "      <td>14.16</td>\n",
       "      <td>495.10</td>\n",
       "      <td>884.01</td>\n",
       "      <td>1417.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>4.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>490.00</td>\n",
       "      <td>734.50</td>\n",
       "      <td>1264.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.03</td>\n",
       "      <td>9.65</td>\n",
       "      <td>95.41</td>\n",
       "      <td>740.71</td>\n",
       "      <td>746.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        카테고리     제목      내용       목차       전체\n",
       "min     0.00   1.00  135.00     0.00   323.00\n",
       "max     4.00  75.00  861.00  6677.00  7296.00\n",
       "mean    3.52  14.16  495.10   884.01  1417.79\n",
       "median  4.00  11.00  490.00   734.50  1264.50\n",
       "std     1.03   9.65   95.41   740.71   746.49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 전체 텍스트 길이 백분위수 ===\n",
      "25번째 백분위: 881자\n",
      "50번째 백분위: 1264자\n",
      "75번째 백분위: 1758자\n",
      "90번째 백분위: 2343자\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 각 도서별 텍스트 길이 계산\n",
    "text_lengths = []\n",
    "for book in books:\n",
    "    text = f\"카테고리: {book['category_name']}\\n제목: {book['title']}\\n내용: {book['contents']}\\n목차: {book['table_of_contents']}\"\n",
    "    length_info = {\n",
    "        '카테고리': len(book['category_name']),\n",
    "        '제목': len(book['title']),\n",
    "        '내용': len(book['contents']),\n",
    "        '목차': len(book['table_of_contents']),\n",
    "        '전체': len(text)\n",
    "    }\n",
    "    text_lengths.append(length_info)\n",
    "\n",
    "# DataFrame으로 변환\n",
    "df_lengths = pd.DataFrame(text_lengths)\n",
    "\n",
    "# 기본 통계 계산\n",
    "stats = df_lengths.agg(['min', 'max', 'mean', 'median', 'std']).round(2)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n=== 각 필드별 텍스트 길이 통계 ===\")\n",
    "display(stats)\n",
    "\n",
    "# 백분위수 계산\n",
    "percentiles = df_lengths['전체'].quantile([0.25, 0.5, 0.75, 0.9])\n",
    "print(\"\\n=== 전체 텍스트 길이 백분위수 ===\")\n",
    "for p, v in percentiles.items():\n",
    "    print(f\"{int(p*100)}번째 백분위: {int(v)}자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 사용자 정보\n",
    "\n",
    "사용자 정보는 사용자가 읽은 책 정보와 사용자의 책 취향 정보를 사용한다.\n",
    "\n",
    "#### 1. 사용자가 읽은 책 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 도서 1:\n",
      "  title: 완벽이라는 중독 : 불안한 완벽주의자를 위한 심리학\n",
      "  author: 토머스 커런 지음 ;김문주 옮김\n",
      "  rating: 4.5\n",
      "  review: 심리학적 관점에서 자아를 이해하는데 도움이 됨\n",
      "  read_date: 2024-01-05\n",
      "  genre: ['심리학', '자기계발']\n",
      "\n",
      "📚 도서 2:\n",
      "  title: 침묵을 배우는 시간 : 말이 넘쳐나는 세상 속, 더욱 빛을 발하는 침묵의 품격\n",
      "  author: 코르넬리아 토프 지음 ;장혜경 옮김\n",
      "  rating: 4.0\n",
      "  review: 따뜻한 위로가 되는 에세이\n",
      "  read_date: 2024-01-15\n",
      "  genre: ['에세이', '자기계발']\n",
      "\n",
      "📚 도서 3:\n",
      "  title: 나답게 산다는 것 : 나를 찾고자 하는 이들의 철학수업\n",
      "  author: 박은미 지음\n",
      "  rating: 4.5\n",
      "  review: 쉽게 읽을 수 있는 철학 에세이\n",
      "  read_date: 2024-01-25\n",
      "  genre: ['철학', '에세이']\n",
      "\n",
      "📚 도서 4:\n",
      "  title: 출근길 심리학 : 단단하고 유연한 멘탈을 위한 33가지 마음의 법칙\n",
      "  author: 반유화 지음\n",
      "  rating: 3.5\n",
      "  review: 일상적인 심리학 이야기\n",
      "  read_date: 2024-02-05\n",
      "  genre: ['심리학', '자기계발']\n",
      "\n",
      "📚 도서 5:\n",
      "  title: 내가 누구인지 아는 것이 왜 중요한가\n",
      "  author: 페터 베르 지음 ;장혜경 옮김\n",
      "  rating: 4.0\n",
      "  review: 자아 성찰에 도움이 되는 책\n",
      "  read_date: 2024-02-15\n",
      "  genre: ['심리학', '에세이']\n",
      "\n",
      "📚 도서 6:\n",
      "  title: 자화상 내 마음을 그리다\n",
      "  author: 김선현 지음\n",
      "  rating: 3.5\n",
      "  review: 마음을 따뜻하게 해주는 이야기\n",
      "  read_date: 2024-02-25\n",
      "  genre: ['에세이']\n",
      "\n",
      "📚 도서 7:\n",
      "  title: 각본 없음 : 삶의 다음 페이지로 넘어가기 위해 쓴 것들\n",
      "  author: 아비 모건 지음 ;이유림 옮김\n",
      "  rating: 4.0\n",
      "  review: 일상의 소소한 위로\n",
      "  read_date: 2024-03-05\n",
      "  genre: ['에세이', '자기계발']\n",
      "\n",
      "📚 도서 8:\n",
      "  title: 세상에서 가장 긴 행복 탐구 보고서\n",
      "  author: 로버트 월딩거,마크 슐츠 지음\n",
      "  rating: 3.5\n",
      "  review: 행복에 대한 심리학적 탐구\n",
      "  read_date: 2024-03-15\n",
      "  genre: ['심리학', '자기계발']\n",
      "\n",
      "📚 도서 9:\n",
      "  title: (쇼펜하우어의) 고독한 행복\n",
      "  author: 아르투어 쇼펜하우어 지음\n",
      "  rating: 3.0\n",
      "  review: 철학적 관점의 삶의 이야기\n",
      "  read_date: 2024-03-25\n",
      "  genre: ['철학', '에세이']\n",
      "\n",
      "📚 도서 10:\n",
      "  title: 나의 문학 답사 일지 : 배움을 찾아 떠난 국문학자의 여행\n",
      "  author: 정병설 지음\n",
      "  rating: 4.0\n",
      "  review: 따뜻한 감성의 여행 에세이\n",
      "  read_date: 2024-04-01\n",
      "  genre: ['에세이', '여행']\n"
     ]
    }
   ],
   "source": [
    "with open('./data/test-case/user_reading_history.json', 'r', encoding='utf-8') as f:\n",
    "    reading_history = json.load(f)\n",
    "\n",
    "for i, book in enumerate(reading_history['read_books'], 1):\n",
    "    print(f\"\\n📚 도서 {i}:\")\n",
    "    for key, value in book.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 사용자의 책 취향 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 선호 장르:\n",
      "  - 심리학 (가중치: 0.8)\n",
      "  - 자기계발 (가중치: 0.7)\n",
      "  - 에세이 (가중치: 0.6)\n",
      "\n",
      "📖 독서 스타일:\n",
      "  - preferred_length: 중간\n",
      "  - complexity_level: 쉬움\n",
      "  - tone: 따뜻함\n",
      "\n",
      "🔑 관심 키워드:\n",
      "  불안, 힐링, 위로, 심리, 일상\n",
      "\n",
      "⛔ 기피 주제:\n",
      "  우울, 공포, 긴장감\n"
     ]
    }
   ],
   "source": [
    "with open('./data/test-case/user_reading_preferences.json', 'r', encoding='utf-8') as f:\n",
    "    reading_preferences = json.load(f)\n",
    "\n",
    "preferences = reading_preferences['preferences']\n",
    "\n",
    "print(\"\\n📚 선호 장르:\")\n",
    "for genre in preferences['genres']:\n",
    "    print(f\"  - {genre['name']} (가중치: {genre['weight']})\")\n",
    "\n",
    "print(\"\\n📖 독서 스타일:\")\n",
    "for key, value in preferences['reading_style'].items():\n",
    "    print(f\"  - {key}: {value}\")\n",
    "\n",
    "print(\"\\n🔑 관심 키워드:\")\n",
    "print(f\"  {', '.join(preferences['keywords'])}\")\n",
    "\n",
    "print(\"\\n⛔ 기피 주제:\")\n",
    "print(f\"  {', '.join(preferences['avoid_topics'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 DB 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인 및 디바이스 설정\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    device_map = {'': 0}\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    device_map = {'': device}\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    device_map = {'': device}\n",
    "\n",
    "print(f\"사용 디바이스: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도서 정보 벡터 DB 생성 완료: 2201개 문서\n",
      "독서 이력 벡터 DB 생성 완료: 10개 문서\n",
      "독서 취향 벡터 DB 생성 완료: 1개 문서\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "import json\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': device}\n",
    ")\n",
    "\n",
    "#--------------------- 1. 도서 정보 벡터 DB ---------------------\n",
    "with open('./data/library_books.json', 'r', encoding='utf-8') as f:\n",
    "    books = json.load(f)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "book_documents = []\n",
    "for book in books:\n",
    "    text = f\"카테고리: {book['category_name']}\\n제목: {book['title']}\\n내용: {book['contents']}\\n목차: {book['table_of_contents']}\"\n",
    "    \n",
    "    metadata = {\n",
    "        'title': book['title'],\n",
    "        'category': book['category_name'],\n",
    "        'author': book['author'],\n",
    "        'isbn': book['isbn'],\n",
    "        'publish_year': book['publish_year'],\n",
    "    }\n",
    "    \n",
    "    chunks = text_splitter.create_documents(\n",
    "        texts=[text],\n",
    "        metadatas=[metadata]\n",
    "    )\n",
    "    book_documents.extend(chunks)\n",
    "\n",
    "# 도서 정보 벡터 DB 생성\n",
    "books_vectorstore = Chroma.from_documents(\n",
    "    documents=book_documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"books_collection\"\n",
    ")\n",
    "\n",
    "print(f\"도서 정보 벡터 DB 생성 완료: {len(book_documents)}개 문서\")\n",
    "\n",
    "#--------------------- 2. 독서 이력 벡터 DB ---------------------\n",
    "with open('./data/test-case/user_reading_history.json', 'r', encoding='utf-8') as f:\n",
    "    reading_history = json.load(f)\n",
    "\n",
    "history_documents = []\n",
    "for book in reading_history['read_books']:\n",
    "    text = f\"제목: {book['title']}\\n저자: {book['author']}\\n평점: {book['rating']}\\n리뷰: {book['review']}\\n장르: {', '.join(book['genre'])}\\n읽은 날짜: {book['read_date']}\"\n",
    "    \n",
    "    metadata = {\n",
    "        'title': book['title'],\n",
    "        'author': book['author'],\n",
    "        'rating': book['rating'],\n",
    "        'genre_str': ', '.join(book['genre']),\n",
    "        'read_date': book['read_date']\n",
    "    }\n",
    "    \n",
    "    doc = Document(page_content=text, metadata=metadata)\n",
    "    history_documents.append(doc)\n",
    "\n",
    "# 독서 이력 벡터 DB 생성\n",
    "history_vectorstore = Chroma.from_documents(\n",
    "    documents=history_documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"reading_history_collection\"\n",
    ")\n",
    "\n",
    "print(f\"독서 이력 벡터 DB 생성 완료: {len(history_documents)}개 문서\")\n",
    "\n",
    "#--------------------- 3. 독서 취향 벡터 DB ---------------------\n",
    "with open('./data/test-case/user_reading_preferences.json', 'r', encoding='utf-8') as f:\n",
    "    reading_preferences = json.load(f)\n",
    "\n",
    "preferences_text = f\"선호 장르: {', '.join([f'{g['name']}({g['weight']})' for g in reading_preferences['preferences']['genres']])}\\n\"\n",
    "preferences_text += f\"독서 스타일: 길이({reading_preferences['preferences']['reading_style']['preferred_length']}), \"\n",
    "preferences_text += f\"복잡도({reading_preferences['preferences']['reading_style']['complexity_level']}), \"\n",
    "preferences_text += f\"톤({reading_preferences['preferences']['reading_style']['tone']})\\n\"\n",
    "preferences_text += f\"관심 키워드: {', '.join(reading_preferences['preferences']['keywords'])}\\n\"\n",
    "preferences_text += f\"기피 주제: {', '.join(reading_preferences['preferences']['avoid_topics'])}\"\n",
    "\n",
    "preferences_metadata = {\n",
    "    'genres_str': ', '.join([g['name'] for g in reading_preferences['preferences']['genres']]),\n",
    "    'keywords_str': ', '.join(reading_preferences['preferences']['keywords']),\n",
    "    'avoid_topics_str': ', '.join(reading_preferences['preferences']['avoid_topics'])\n",
    "}\n",
    "\n",
    "preferences_doc = Document(page_content=preferences_text, metadata=preferences_metadata)\n",
    "\n",
    "# 독서 취향 벡터 DB 생성 (단일 문서)\n",
    "preferences_vectorstore = Chroma.from_documents(\n",
    "    documents=[preferences_doc],\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"reading_preferences_collection\"\n",
    ")\n",
    "\n",
    "print(\"독서 취향 벡터 DB 생성 완료: 1개 문서\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추천 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공통 프롬프트를 작성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 공통 기본 프롬프트 템플릿\n",
    "BASE_RECOMMENDATION_TEMPLATE = \"\"\"당신은 사용자의 독서 취향과 감정 상태에 맞춰 도서를 추천하는 전문가입니다.\n",
    "다음 정보를 분석하여 사용자에게 가장 적합한 {num_recommendations}권의 책을 추천해주세요.\n",
    "\n",
    "## 사용자 정보\n",
    "- 현재 감정 상태: {user_emotion}\n",
    "- 원하는 감정적 효과: {desired_emotional_effect}\n",
    "- 직업: {occupation}\n",
    "- 독서 상황: {reading_context}\n",
    "- 선호하는 집중도: {focus_level}\n",
    "\n",
    "## 사용자 취향 정보\n",
    "{preferences}\n",
    "\n",
    "## 사용자가 읽은 관련 책들\n",
    "{reading_history}\n",
    "\n",
    "## 후보 도서 목록\n",
    "{candidate_books}\n",
    "\n",
    "다음과 같은 척도로 각 후보 도서를 평가하세요:\n",
    "1. 사용자의 현재 감정 상태와 원하는 감정적 효과와의 적합성\n",
    "2. 사용자의 취향과의 일치도 (장르, 스타일, 선호 키워드)\n",
    "3. 사용자의 기피 주제와 겹치지 않는지 여부\n",
    "4. 사용자의 독서 이력과의 연관성\n",
    "5. 독서 상황과 선호하는 집중도에 맞는지 여부\n",
    "6. 사용자의 직업과 관련된 통찰이나 도움이 될 수 있는지 여부\n",
    "\n",
    "최종 추천은 다음 형식으로 제시해주세요:\n",
    "1. [첫 번째 추천 도서 제목] - 저자\n",
    "   - 추천 이유: (사용자의 현재 감정과 원하는 효과를 고려한 구체적인 이유)\n",
    "   - 이 책이 도움이 될 수 있는 이유: (감정적 효과나 얻을 수 있는 통찰 등)\n",
    "\n",
    "2. [두 번째 추천 도서 제목] - 저자\n",
    "   - 추천 이유: (사용자의 현재 감정과 원하는 효과를 고려한 구체적인 이유)\n",
    "   - 이 책이 도움이 될 수 있는 이유: (감정적 효과나 얻을 수 있는 통찰 등)\n",
    "\n",
    "3. [세 번째 추천 도서 제목] - 저자\n",
    "   - 추천 이유: (사용자의 현재 감정과 원하는 효과를 고려한 구체적인 이유)\n",
    "   - 이 책이 도움이 될 수 있는 이유: (감정적 효과나 얻을 수 있는 통찰 등)\n",
    "\"\"\"\n",
    "\n",
    "# 공통 프롬프트 템플릿 생성\n",
    "base_prompt_template = ChatPromptTemplate.from_template(BASE_RECOMMENDATION_TEMPLATE)\n",
    "\n",
    "# 포맷팅 함수는 동일하게 유지\n",
    "def format_reading_history(reading_history_data):\n",
    "    if not reading_history_data:\n",
    "        return \"관련 독서 이력이 없습니다.\"\n",
    "    \n",
    "    # 다단계 RAG 결과 포맷팅\n",
    "    if isinstance(reading_history_data, list) and all(isinstance(item, dict) and 'metadata' in item for item in reading_history_data):\n",
    "        return \"\\n\\n\".join([\n",
    "            f\"- 도서: {item['metadata'].get('title', '제목 없음')}\\n\"\n",
    "            f\"  저자: {item['metadata'].get('author', '저자 미상')}\\n\"\n",
    "            f\"  장르: {item['metadata'].get('genre_str', '장르 없음')}\\n\"\n",
    "            f\"  평점: {item['metadata'].get('rating', 0)}\\n\"\n",
    "            f\"  내용: {item['content'][:200]}...\"\n",
    "            for item in reading_history_data\n",
    "        ])\n",
    "    \n",
    "    # 직접 벡터 검색 결과 포맷팅\n",
    "    elif isinstance(reading_history_data, list) and all(isinstance(item, dict) and 'title' in item for item in reading_history_data):\n",
    "        return \"\\n\".join([\n",
    "            f\"- '{item['title']}' (저자: {item['author']}, 장르: {item['genre']}, 평점: {item['rating']})\\n  리뷰: {item['review']}\"\n",
    "            for item in reading_history_data\n",
    "        ])\n",
    "    \n",
    "    # 다른 형식의 데이터\n",
    "    return str(reading_history_data)\n",
    "\n",
    "def format_book_candidates(candidates_data):\n",
    "    if not candidates_data:\n",
    "        return \"추천할 만한 후보 도서가 없습니다.\"\n",
    "    \n",
    "    # 다단계 RAG 결과 포맷팅\n",
    "    if isinstance(candidates_data, list) and all(isinstance(item, dict) and 'metadata' in item for item in candidates_data):\n",
    "        return \"\\n\\n\".join([\n",
    "            f\"{i+1}. 제목: {item['metadata'].get('title', '제목 없음')}\\n\"\n",
    "            f\"   저자: {item['metadata'].get('author', '저자 미상')}\\n\"\n",
    "            f\"   카테고리: {item['metadata'].get('category', '카테고리 없음')}\\n\"\n",
    "            f\"   내용: {item['content'][:300]}...\"\n",
    "            for i, item in enumerate(candidates_data)\n",
    "        ])\n",
    "    \n",
    "    # 직접 벡터 검색 결과 포맷팅\n",
    "    elif isinstance(candidates_data, list) and all(isinstance(item, dict) and 'index' in item for item in candidates_data):\n",
    "        return \"\\n\".join([\n",
    "            f\"{book['index']}. '{book['title']}' (저자: {book['author']}, 카테고리: {book['category']})\\n   내용 요약: {book['content'][:200]}...\"\n",
    "            for book in candidates_data\n",
    "        ])\n",
    "    \n",
    "    # 다른 형식의 데이터\n",
    "    return str(candidates_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llm 모델을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    max_tokens=512,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "chain = base_prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. RAG에 기반한 추천 로직"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_stage_rag_search(user_query, num_candidates, num_history_results):\n",
    "    results = {}\n",
    "    \n",
    "    # 1단계: 항상 사용자 취향 정보 검색 (가장 중요)\n",
    "    preference_results = preferences_vectorstore.similarity_search_with_score(user_query, k=1)\n",
    "    if preference_results:\n",
    "        results['user_preferences'] = preference_results[0]\n",
    "    \n",
    "    # 2단계: 사용자의 독서 이력에서 관련 도서 검색\n",
    "    history_results = history_vectorstore.similarity_search_with_score(user_query, k=num_history_results)\n",
    "    if history_results:\n",
    "        results['reading_history'] = history_results\n",
    "    \n",
    "    # 3단계: 독서 이력과 취향 정보를 고려하여 강화된 쿼리 생성\n",
    "    enhanced_query = user_query\n",
    "    \n",
    "    # 취향 정보에서 관련 키워드 추출\n",
    "    if 'user_preferences' in results:\n",
    "        pref_doc = results['user_preferences'][0]\n",
    "        keywords = pref_doc.metadata.get('keywords_str', '')\n",
    "        if keywords:\n",
    "            enhanced_query += f\" 키워드: {keywords}\"\n",
    "    \n",
    "    # 독서 이력에서 높은 평점의 장르 추출\n",
    "    if 'reading_history' in results:\n",
    "        liked_genres = []\n",
    "        for doc, _ in results['reading_history']:\n",
    "            if doc.metadata.get('rating', 0) >= 4.0:\n",
    "                genres = doc.metadata.get('genre_str', '').split(', ')\n",
    "                liked_genres.extend(genres)\n",
    "        \n",
    "        if liked_genres:\n",
    "            unique_genres = list(set(liked_genres))\n",
    "            enhanced_query += f\" 선호 장르: {', '.join(unique_genres[:3])}\"\n",
    "    \n",
    "    print(f\"강화된 쿼리: {enhanced_query}\")\n",
    "    \n",
    "    # 4단계: 강화된 쿼리로 도서 검색\n",
    "    book_results = books_vectorstore.similarity_search_with_score(enhanced_query, k=num_candidates)\n",
    "    results['recommended_books'] = book_results\n",
    "    \n",
    "    # 결과 포맷팅 및 반환\n",
    "    formatted_results = []\n",
    "    \n",
    "    # 사용자 취향 정보\n",
    "    if 'user_preferences' in results:\n",
    "        pref_doc, pref_score = results['user_preferences']\n",
    "        formatted_results.append({\n",
    "            'type': 'user_preferences',\n",
    "            'content': pref_doc.page_content,\n",
    "            'metadata': pref_doc.metadata,\n",
    "            'score': pref_score\n",
    "        })\n",
    "    \n",
    "    # 관련 독서 이력\n",
    "    if 'reading_history' in results:\n",
    "        for i, (hist_doc, hist_score) in enumerate(results['reading_history']):\n",
    "            if i < 2:  # 최대 2개만 포함\n",
    "                formatted_results.append({\n",
    "                    'type': 'reading_history',\n",
    "                    'content': hist_doc.page_content,\n",
    "                    'metadata': hist_doc.metadata,\n",
    "                    'score': hist_score\n",
    "                })\n",
    "    \n",
    "    # 추천 도서\n",
    "    recommended_count = 0\n",
    "    for book_doc, book_score in results['recommended_books']:\n",
    "        formatted_results.append({\n",
    "            'type': 'recommended_book',\n",
    "            'content': book_doc.page_content,\n",
    "            'metadata': book_doc.metadata,\n",
    "            'score': book_score\n",
    "        })\n",
    "        \n",
    "        recommended_count += 1\n",
    "        if recommended_count >= num_candidates - 2:  # 취향과 이력을 포함하고 남은 슬롯 채우기\n",
    "            break\n",
    "    \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_stage_recommendation(user_emotion, desired_emotional_effect, occupation, reading_context, focus_level, num_candidates=8, num_history_results=3, num_recommendations=3):\n",
    "    \"\"\"다단계 RAG 검색 결과를 바탕으로 LLM에 도서 추천을 요청하는 함수\"\"\"\n",
    "    # 감정과 원하는 효과를 기반으로 검색 쿼리 구성\n",
    "    search_query = f\"{user_emotion}을 느끼는 사람이 {desired_emotional_effect}할 수 있는 책\"\n",
    "    \n",
    "    # 다단계 RAG 검색 수행\n",
    "    rag_results = multi_stage_rag_search(search_query, num_candidates, num_history_results)\n",
    "    \n",
    "    # 결과를 타입별로 분류\n",
    "    user_preferences = None\n",
    "    reading_history = []\n",
    "    book_candidates = []\n",
    "    \n",
    "    for item in rag_results:\n",
    "        if item['type'] == 'user_preferences':\n",
    "            user_preferences = item\n",
    "        elif item['type'] == 'reading_history':\n",
    "            reading_history.append(item)\n",
    "        elif item['type'] == 'recommended_book':\n",
    "            book_candidates.append(item)\n",
    "    \n",
    "    # 취향 정보 포맷팅\n",
    "    preferences_formatted = user_preferences['content'] if user_preferences else \"취향 정보가 없습니다.\"\n",
    "    \n",
    "    # 독서 이력 및 후보 도서 포맷팅 (공통 함수 사용)\n",
    "    history_formatted = format_reading_history(reading_history)\n",
    "    candidates_formatted = format_book_candidates(book_candidates)\n",
    "    \n",
    "    result = chain.invoke({\n",
    "        \"user_emotion\": user_emotion,\n",
    "        \"desired_emotional_effect\": desired_emotional_effect,\n",
    "        \"occupation\": occupation,\n",
    "        \"reading_context\": reading_context,\n",
    "        \"focus_level\": focus_level,\n",
    "        \"preferences\": preferences_formatted,\n",
    "        \"reading_history\": history_formatted,\n",
    "        \"candidate_books\": candidates_formatted,\n",
    "        \"num_recommendations\": num_recommendations\n",
    "    })\n",
    "    \n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Prompt 기반의 추천 로직"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 취향 정보 추출 완료\n"
     ]
    }
   ],
   "source": [
    "# 취향 정보를 문자열로 포맷팅 (프롬프트에 직접 사용)\n",
    "preferences_formatted = f\"\"\"\n",
    "## 사용자 독서 취향 정보\n",
    "- 선호 장르: {', '.join([f\"{g['name']}(가중치:{g['weight']})\" for g in reading_preferences['preferences']['genres']])}\n",
    "- 선호 독서 스타일: \n",
    "  * 선호 길이: {reading_preferences['preferences']['reading_style']['preferred_length']}\n",
    "  * 복잡도: {reading_preferences['preferences']['reading_style']['complexity_level']}\n",
    "  * 선호 톤: {reading_preferences['preferences']['reading_style']['tone']}\n",
    "- 관심 키워드: {', '.join(reading_preferences['preferences']['keywords'])}\n",
    "- 기피 주제: {', '.join(reading_preferences['preferences']['avoid_topics'])}\n",
    "\"\"\"\n",
    "\n",
    "print(\"사용자 취향 정보 추출 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_vector_recommendation(user_emotion, desired_emotional_effect, occupation, reading_context, focus_level, num_candidates=8, num_history_results=3, num_recommendations=3):\n",
    "    \"\"\"벡터 DB 직접 검색 결과를 바탕으로 LLM에 도서 추천을 요청하는 함수\"\"\"\n",
    "    # 감정과 원하는 효과를 기반으로 검색 쿼리 구성\n",
    "    search_query = f\"{user_emotion}을 느끼는 사람이 {desired_emotional_effect}할 수 있는 책\"\n",
    "    \n",
    "    # 1. 쿼리에 관련된 도서 검색\n",
    "    book_results = books_vectorstore.similarity_search_with_score(search_query, k=num_candidates)\n",
    "    \n",
    "    # 2. 사용자의 독서 이력 중 관련 있는 책 검색\n",
    "    history_results = history_vectorstore.similarity_search_with_score(search_query, k=num_history_results)\n",
    "    \n",
    "    # 3. 검색 결과 포맷팅\n",
    "    candidate_books = []\n",
    "    for i, (doc, score) in enumerate(book_results):\n",
    "        book_info = {\n",
    "            'index': i+1,\n",
    "            'title': doc.metadata.get('title', '제목 없음'),\n",
    "            'author': doc.metadata.get('author', '저자 미상'),\n",
    "            'category': doc.metadata.get('category', '분류 없음'),\n",
    "            'content': doc.page_content.strip()[:500] + \"...\" if len(doc.page_content) > 500 else doc.page_content.strip(),\n",
    "            'similarity_score': score\n",
    "        }\n",
    "        candidate_books.append(book_info)\n",
    "    \n",
    "    reading_history_formatted = []\n",
    "    for doc, score in history_results:\n",
    "        history_info = {\n",
    "            'title': doc.metadata.get('title', '제목 없음'),\n",
    "            'author': doc.metadata.get('author', '저자 미상'),\n",
    "            'genre': doc.metadata.get('genre_str', '장르 없음'),\n",
    "            'rating': doc.metadata.get('rating', 0),\n",
    "            'review': doc.page_content.split('리뷰: ')[1].split('\\n')[0] if '리뷰: ' in doc.page_content else '리뷰 없음'\n",
    "        }\n",
    "        reading_history_formatted.append(history_info)\n",
    "    \n",
    "    # 독서 이력 및 후보 도서 포맷팅 (공통 함수 사용)\n",
    "    history_formatted = format_reading_history(reading_history_formatted)\n",
    "    candidates_formatted = format_book_candidates(candidate_books)\n",
    "    \n",
    "    result = chain.invoke({\n",
    "        \"user_emotion\": user_emotion,\n",
    "        \"desired_emotional_effect\": desired_emotional_effect,\n",
    "        \"occupation\": occupation,\n",
    "        \"reading_context\": reading_context,\n",
    "        \"focus_level\": focus_level,\n",
    "        \"preferences\": preferences_formatted,  # 사용자 취향 정보 (전역 변수)\n",
    "        \"reading_history\": history_formatted,\n",
    "        \"candidate_books\": candidates_formatted,\n",
    "        \"num_recommendations\": num_recommendations\n",
    "    })\n",
    "    \n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_recommendations(user_emotion, desired_emotional_effect, occupation, reading_context, focus_level, method=\"both\"):\n",
    "    print(f\"현재 감정 상태: {user_emotion}\")\n",
    "    print(f\"원하는 감정적 효과: {desired_emotional_effect}\")\n",
    "    print(f\"직업: {occupation}\")\n",
    "    print(f\"독서 상황: {reading_context}\")\n",
    "    print(f\"선호하는 집중도: {focus_level}\")\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    num_candidates = 6\n",
    "    num_history_results = 3\n",
    "    num_recommendations = 3\n",
    "    \n",
    "    if method in [\"multi_stage\", \"both\"]:\n",
    "        print(\"\\n다단계 RAG 기반 추천 도서를 찾는 중...\\n\")\n",
    "        multi_stage_result = multi_stage_recommendation(\n",
    "            user_emotion=user_emotion,\n",
    "            desired_emotional_effect=desired_emotional_effect,\n",
    "            occupation=occupation,\n",
    "            reading_context=reading_context,\n",
    "            focus_level=focus_level,\n",
    "            num_candidates=num_candidates,\n",
    "            num_history_results=num_history_results,\n",
    "            num_recommendations=num_recommendations\n",
    "        )\n",
    "        results[\"multi_stage\"] = multi_stage_result\n",
    "    \n",
    "    if method in [\"direct\", \"both\"]:\n",
    "        print(\"\\n직접 벡터 검색 기반 추천 도서를 찾는 중...\\n\")\n",
    "        direct_result = direct_vector_recommendation(\n",
    "            user_emotion=user_emotion,\n",
    "            desired_emotional_effect=desired_emotional_effect,\n",
    "            occupation=occupation,\n",
    "            reading_context=reading_context,\n",
    "            focus_level=focus_level,\n",
    "            num_candidates=num_candidates,\n",
    "            num_history_results=num_history_results,\n",
    "            num_recommendations=num_recommendations\n",
    "        )\n",
    "        results[\"direct\"] = direct_result\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 감정 상태: 불안함\n",
      "원하는 감정적 효과: 위로와 안정감\n",
      "직업: 직장인\n",
      "독서 상황: 잠들기 전 독서\n",
      "선호하는 집중도: 가볍게 읽을 수 있는 책\n",
      "\n",
      "다단계 RAG 기반 추천 도서를 찾는 중...\n",
      "\n",
      "강화된 쿼리: 불안함을 느끼는 사람이 위로와 안정감할 수 있는 책 키워드: 불안, 힐링, 위로, 심리, 일상 선호 장르: 에세이, 여행\n",
      "\n",
      "직접 벡터 검색 기반 추천 도서를 찾는 중...\n",
      "\n",
      "\n",
      "=== 다단계 RAG 기반 도서 추천 결과 ===\n",
      "\n",
      "1. **[불안해 보여서 불안한 당신에게] - 한창욱**\n",
      "   - 추천 이유: 이 책은 불안한 청춘들을 위로하고, 그들의 감정을 이해해 주는 에피소드들로 구성되어 있습니다. 사용자가 현재 느끼고 있는 불안감에 공감하며, 이를 덜어줄 수 있는 따뜻한 메시지를 담고 있습니다. \n",
      "   - 이 책이 도움이 될 수 있는 이유: 다양한 사례를 통해 불안의 원인과 그에 대한 대처 방안을 제시하므로, 사용자가 느끼는 감정에 대한 이해와 위로를 제공할 수 있습니다. 또한, 일상에서의 불안감을 해소하는 데 필요한 통찰을 얻을 수 있습니다.\n",
      "\n",
      "2. **[잠깐 머리 좀 식히고 오겠습니다] - 윤대현**\n",
      "   - 추천 이유: 이 책은 스트레스 관리와 마음의 안정을 위한 심리 처방전을 제공하며, 직장인으로서의 일상에서 느끼는 불안감을 이해하고 극복하는 데 도움을 줄 수 있습니다. \n",
      "   - 이 책이 도움이 될 수 있는 이유: 저자가 제시하는 다양한 팁과 조언은 직장 생활에서의 스트레스를 줄이고 자존감을 높이는 데 유용하며, 가벼운 문체로 쉽게 읽을 수 있어 잠들기 전 독서에 적합합니다.\n",
      "\n",
      "3. **[자화상 내 마음을 그리다] - 김선현**\n",
      "   - 추천 이유: 사용자가 이미 읽고 긍정적인 평가를 한 책으로, 따뜻한 이야기로 마음을 위로해 줄 수 있는 내용을 담고 있습니다. 이 책은 감정의 깊이를 이해하고 일상에서 느끼는 불안을 해소하는 데 도움을 줄 것입니다.\n",
      "   - 이 책이 도움이 될 수 있는 이유: 이미 긍정적인 경험이 있는 책이므로, 비슷한 느낌의 감정적 안정과 위로를 제공할 것으로 예상됩니다. 또한, 심리학적인 관점에서 일상적인 문제를 다루고 있어 사용자의 관심과 잘 맞아떨어집니다.\n",
      "\n",
      "=== 직접 벡터 검색 기반 도서 추천 결과 ===\n",
      "\n",
      "사용자의 독서 취향과 감정 상태를 고려하여 다음과 같은 도서를 추천드립니다.\n",
      "\n",
      "1. **[정조처럼 소통하라] - 저자: 정창권**\n",
      "   - 추천 이유: 이 책은 소통의 중요성과 따뜻한 인간관계에 대한 이야기를 다룹니다. 현재 불안한 감정을 가진 사용자에게 소통과 이해를 통한 위로와 안정감을 제공할 수 있습니다.\n",
      "   - 이 책이 도움이 될 수 있는 이유: 소통의 기술을 배우고, 주변 사람들과의 관계를 개선하는 데 도움이 될 수 있습니다. 이는 사용자에게 심리적 안정을 주고, 불안감을 덜어주는 데 기여할 것입니다.\n",
      "\n",
      "2. **[보고 생각하고 느끼는 우리 명승기행] - 저자: 김학범**\n",
      "   - 추천 이유: 이 책은 한국의 아름다운 명승지를 소개하며, 일상에서 벗어나 자연의 아름다움을 느끼게 해줍니다. 불안한 마음을 안정시키고 힐링의 효과를 줄 수 있는 따뜻한 내용입니다.\n",
      "   - 이 책이 도움이 될 수 있는 이유: 자연과 문화에 대한 에세이는 독서 중에 편안함을 제공하며, 사용자가 잠들기 전 읽기에 적합합니다. 일상에서 느끼는 불안감을 잊고 마음의 여유를 찾는 데 도움을 줄 것입니다.\n",
      "\n",
      "3. **[자화상 내 마음을 그리다] - 저자: 김선현**\n",
      "   - 추천 이유: 사용자가 이미 읽고 긍정적인 반응을 보인 책으로, 마음을 따뜻하게 해주는 이야기로 불안함을 덜어줄 수 있습니다. 감정적으로 친숙한 내용이 사용자에게 안정감을 줄 것입니다.\n",
      "   - 이 책이 도움이 될 수 있는 이유: 사용자에게 위로와 공감을 제공하며, 독서 후 편안한 마음가짐을 갖게 해 줄 것입니다. 또한 잠들기 전 읽기에 적합하여 독서 상황과 잘 맞습니다.\n",
      "\n",
      "이 도서들은 사용자의 불안한 감정 상태를 위로하고, 안정감을 줄 수 있는 내용을 담고 있어 추천합니다.\n"
     ]
    }
   ],
   "source": [
    "# 테스트 시나리오 (README.md의 TestCase1에 맞게 수정)\n",
    "test_results = get_book_recommendations(\n",
    "    user_emotion=\"불안함\",                      # 질문 1 응답\n",
    "    desired_emotional_effect=\"위로와 안정감\",     # 질문 2 응답\n",
    "    occupation=\"직장인\",                       # 질문 3 응답\n",
    "    reading_context=\"잠들기 전 독서\",            # 질문 4 응답\n",
    "    focus_level=\"가볍게 읽을 수 있는 책\",         # 질문 5 응답\n",
    "    method=\"both\"  # 두 방식 모두 사용\n",
    ")\n",
    "\n",
    "print(\"\\n=== 다단계 RAG 기반 도서 추천 결과 ===\\n\")\n",
    "print(test_results.get(\"multi_stage\", \"결과 없음\"))\n",
    "\n",
    "print(\"\\n=== 직접 벡터 검색 기반 도서 추천 결과 ===\\n\")\n",
    "print(test_results.get(\"direct\", \"결과 없음\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
