## [8주차] 심화과제 - 나만의 LLM 서비스에 경량화 기법들 적용해보기

### 프로젝트 : 감정 기반 도서 추천 서비스

챗봇 질문을 기반으로 사용자에게 도서를 추천하는 서비스

**❓질문 예시**

1. 현재 감정 상태 파악 Q: "지금 당신의 기분을 가장 잘 설명하는 단어는 무엇인가요?" A: 행복함, 지침, 불안함, 우울함, 설렘, 혼란스러움 등

2. 원하는 감정적 효과 Q: "지금 이 책을 통해 어떤 감정을 경험하고 싶으신가요?" A: 현실 도피하고 싶은지 공감받고 싶은지 위로받고 싶은지 영감과 동기부여를 얻고 싶은지 새로운 시각이 필요한지

3. 직업 정보 Q: "현재 어떤 직업을 가지고 계신가요?" A: 학생, 직장인, 프리랜서, 주부, 구직자 등

4. 현재 상황/컨텍스트 Q: "지금 어떤 상황에서 독서를 하실 예정인가요?" A: 잠들기 전 휴식 이동 중 짧은 시간 주말 여유로운 시간 스트레스 해소를 위한 시간

5. 집중도/몰입도 선호 Q: "지금 어느 정도의 집중도가 필요한 책을 원하시나요?" A: 가볍게 읽을 수 있는 책 깊은 사고가 필요한 책 빠르게 몰입할 수 있는 책

**❗️답변 예시**

1. **'잠깐 머리 좀 식히고 오겠습니다'** - 윤대현

   - 추천 이유: 이 책은 스트레스와 불안감을 관리하는 방법에 대한 심리적 처방을 제공하며, 독자가 겪고 있는 불안함을 이해하고 위로해 줄 수 있습니다. 저자는 직장생활과 인간관계에서 오는 스트레스를 다루며, 공감과 위안을 통해 독자의 마음을 안정시켜 줄 것입니다.
   - 이 책이 도움이 될 수 있는 이유: 직장인으로서 일상에서 느끼는 스트레스에 대한 구체적인 사례와 긍정적인 마음을 심어줄 수 있는 조언이 담겨 있어, 독자가 스스로 위로받고 일상에서 겪는 불안을 덜어내는 데 큰 도움이 될 것입니다.

2. **'나에게 오늘을 선물합니다'** - 김나위

   - 추천 이유: 이 책은 힘든 순간에 자신을 위로하는 방법과 함께, 우리가 혼자가 아니라는 사실을 깨닫게 해줍니다. 불안한 감정 상태를 가진 독자에게 큰 위로와 안정감을 제공할 수 있는 내용이 담겨 있습니다.
   - 이 책이 도움이 될 수 있는 이유: 일상에서 겪는 어려움에 대한 다른 사람들의 이야기를 통해 공감하고 위로받을 수 있으며, 스스로를 돌아보는 시간을 가질 수 있어 감정적 안정감을 찾는 데 기여할 것입니다.

3. **'마음은 괜찮냐고 시가 물었다 : 시 읽어주는 정신과 의사가 건네는 한 편의 위로'** - 황인환
   - 추천 이유: 이 책은 정신건강 전문의가 쓴 시를 통해 독자의 마음을 위로하고, 복잡한 감정을 이해하도록 돕습니다. 독자가 느끼는 불안과 외로움을 공감하며, 그것들을 치유하는 방법을 제시합니다.
   - 이 책이 도움이 될 수 있는 이유: 시를 통해 감정을 표현하고 이해하는 과정은 독자에게 큰 위로가 될 수 있으며, 잠들기 전 편안한 마음으로 읽기 좋습니다. 각 시가 독자의 감정에 깊이 다가가 안정감을 줄 것입니다.

#### ✅ 구현 방법

RAG + GPT API 사용

**RAG DATA**
국립중앙도서관 사서추천도서 (./data/library_books.json)

사용자가 읽은 책 정보 (./data/test-case/user_reading_history.json)

사용자의 책 취향 정보 (./data/test-case/user_reading_preferences.json)

**방법1: RAG 기반 추천 로직**

1. 사용자의 취향 정보, 사용자의 독서 이력 벡터 db에서 질문과 유사한 정보 검색
2. 검색된 정보를 바탕으로 강화된 질문 생성
3. 강화된 질문으로 도서 정보 벡터 db에서 유사한 도서 검색
4. 프롬프트에 검색된 도서 정보를 포함하여 추천 도서 선정

**방법2: 프롬프트 기반 추천 로직**

1. 도서 정보 벡터 db에서 질문과 유사한 도서 검색
2. 프롬프트에 사용자의 취향 정보, 사용자의 독서 이력, 검색된 도서 정보를 포함하여 추천 도서 선정

#### ✅ 평가 방법

1. 추천 도서를 알라딘 API를 통해 상세 정보 검색
2. 검색된 도서 정보를 포함해 평가용 프롬프트 생성
3. Claude 3.7을 통해 평가 진행

- 0~5점 사이로 적합도 평가(존재하지 않는 책의 경우 0점)하고 평균 계산

| 모델        | 방법                 | 추천 도서 후보군 수(num_candidates) | 평균 적합도 | prompt_tokens | completion_tokens | total_cost   |
| ----------- | -------------------- | ----------------------------------- | ----------- | ------------- | ----------------- | ------------ |
| gpt-4o-mini | RAG 기반(방법1)      | 6                                   | 4.77        | 1769          | 417               | 0.0005155499 |
| gpt-4o-mini | 프롬프트 기반(방법2) | 6                                   | 3           | 5747          | 442               | 0.00112725   |

**⚠️ RAG 기반 추천 방법이 비용도 덜 들고 더 적합한 책을 추천해주는 것을 확인할 수 있었음**

[README](https://github.com/paran22/book-recommendation-backend/blob/main/README.md)

[GPT API 사용 코드](https://github.com/paran22/book-recommendation-backend/blob/main/book-recommandation.ipynb)

### 과제 구현

#### ✅ 과제 목표

제한된 환경에서 더 큰 LLM 모델을 사용하고자 함

colab 무료 버전에서 LoRA를 사용해서 더 큰 모델 사용

#### ✅ 과제 구현 결과

[학습 데이터](https://github.com/paran22/book-recommendation-backend/blob/main/data/corpus.json)

[LoRA 테스트 코드](https://github.com/paran22/book-recommendation-backend/blob/main/book-recommandation-llm.ipynb)

colab 무료버전에서는 gpt-large 모델 out of memory로 사용 불가

LoRA를 적용하여 gpt2-lg gpt2-xl, facebook/opt-1.3b, gemma-2b-it 모델 사용 가능 확인
-> 경량화를 통해 동일한 환경에서도 더 큰 모델을 사용할 수 있다는 것을 확인할 수 있음

| 모델              | train/loss         | train/runtime | eval/loss         | eval/runtime | Max alloc |
| ----------------- | ------------------ | ------------- | ----------------- | ------------ | --------- |
| gemma-2b-it       | 3.1014             | 48.3997       | 3.05684232711792  | 1.0529       | 8.2 GB    |
| facebook/opt-1.3b | 1.402118593851725  | 59.7179       | 1.163001298904419 | 0.6428       | 3.4 GB    |
| gpt2-xl           | 1.5866142463684083 | 87.9429       | 1.267969012260437 | 1.1709       |           |

![W B Chart 2025  5  22  오전 10_02_41](https://github.com/user-attachments/assets/571c23dd-cf3f-4402-be66-c30e75305bce)

![W B Chart 2025  5  22  오전 10_02_31](https://github.com/user-attachments/assets/7609a86f-5652-4d63-8355-55d068ca66b1)

모델에 따라 runtime과 loss는 다르게 확인됨
- 테스트한 모델 중 가장 큰 모델인 gemma-2b-it은 loss는 다른 모델들과 다르게 높게 나옴
- facebook/opt-1.3b와 gpt2-xl는 유사한 loss 확인됨
- runtime은 gemma-2b-it와 gpt2-xl가 유사하고, facebook/opt-1.3b이 가장 낮게 나옴
-> 동일한 LoRA 코드를 사용했기 때문에 학습률, batch size 등 모델별 최적화가 필요
  loss만으로 성능을 판단하기는 어려우며, 성능에 대한 추가 검토 필요함




