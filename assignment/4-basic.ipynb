{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4주차] 기본과제 - HuggingFace로 두 문장의 논리적 모순 분류하기\n",
    "\n",
    "MNLI는 두 문장이 주어졌을 때 논리적으로 연결이 되어 있는지, 서로 모순되는지, 아니면 아예 무관한지 분류하는 문제이다.\n",
    "\n",
    "- **입력**: premise에 해당하는 문장과 hypothesis에 해당하는 문장 두 개가 입력으로 들어옵니다.\n",
    "- **출력:** 분류 문제로, 두 문장이 들어왔을 때 다음 세 가지를 예측하시면 됩니다.\n",
    "    - **Entailment:** 두 문장에 논리적 모순이 없습니다.\n",
    "    - **Neutral:** 두 문장은 논리적으로 관련이 없습니다.\n",
    "    - **Contradiction:** 두 문장 사이에 논리적 모순이 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (4.51.1)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: evaluate in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from aiohttp->datasets) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/welcomedl/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets numpy matplotlib evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "허깅페이스를 통해 mnli 데이터셋을 로드한다.\n",
    "\n",
    "- train: 모델 학습을 위한 주 데이터셋으로, 다양한 장르의 텍스트로 구성\n",
    "- validation_matched: 모델 성능 평가를 위한 검증 데이터셋으로, 학습의 데이터와 같은 장르의 텍스트로 구성된다. 모델이 학습한 도메인에서 얼마나 잘 작동하는지 평가한다.\n",
    "- validation_mismatched: 모델 성능 평가를 위한 검증 데이터셋으로, 학습 데이터와 다른 장르의 텍스트로 구성된다. 모델이 새로운 도메인에서 얼마나 잘 작동하는지 평가한다.\n",
    "- test_matched: 최종 테스트용 데이터셋으로, 학습 데이터와 같은 장르의 텍스트로 구성된다.\n",
    "- test_mismatched: 최종 테스트용 데이터셋으로, 학습 데이터와 다른 장르의 텍스트로 구성된다.\n",
    "\n",
    "학습에 사용한 train 데이터는 392702개, 검증에 사용한 validation_matched 데이터는 9815개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "    test_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9796\n",
       "    })\n",
       "    test_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9847\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli = load_dataset(\"nyu-mll/glue\", \"mnli\")\n",
    "mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.',\n",
       " 'hypothesis': 'Product and geography are what make cream skimming work. ',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa 토크나이저를 로드하여 데이터셋에 적용한다.\n",
    "\n",
    "학습에 사용한 데이터셋은 전체의 5%로만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# RoBERTa 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# MNLI 데이터셋을 위한 전처리 함수\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(\n",
    "        data['premise'],\n",
    "        data['hypothesis'],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        # 허깅페이스의 Trainer가 자동으로 필요한 시점에 tensor로 변환하므로 None 처리\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "# 데이터셋 토크나이징\n",
    "tokenized_mnli = mnli['train'].map(preprocess_function, batched=True)\n",
    "tokenized_validation_matched = mnli['validation_matched'].map(preprocess_function, batched=True)\n",
    "tokenized_test_matched = mnli['test_matched'].map(preprocess_function, batched=True)\n",
    "tokenized_test_mismatched = mnli['test_mismatched'].map(preprocess_function, batched=True)\n",
    "\n",
    "# 데이터셋의 5%만 사용\n",
    "train_size = len(tokenized_mnli) // 20    # 약 19,635개\n",
    "val_size = len(tokenized_validation_matched) // 20   # 약 490개\n",
    "\n",
    "train_dataset = tokenized_mnli.shuffle(seed=42).select(range(train_size))\n",
    "validation_dataset = tokenized_validation_matched.shuffle(seed=42).select(range(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토크나이징한 결과 input_ids와 attention_mask가 추가된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['premise', 'hypothesis', 'label', 'idx', 'input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_mnli[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 정의와 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 평가할 메트릭을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "# entailment, contradiction, neutral\n",
    "num_labels = 3\n",
    "\n",
    "# RoBERTa 모델 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'roberta-base',\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "# 분류기(classifier)를 제외한 모든 레이어 동결\n",
    "for param in model.roberta.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 평가 메트릭 정의\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = load(\"glue\", \"mnli\")\n",
    "    # logits: 모델의 원시 출력값 (shape: [batch_size, 3])\n",
    "    # labels: 실제 정답 레이블 (shape: [batch_size])\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    metrics = metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return {\n",
    "        \"eval_accuracy\": metrics[\"accuracy\"]  # accuracy를 eval_accuracy로 변환\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습할 때 early stopping을 사용하기 위해 callback을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# EarlyStopping 콜백 정의\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=2,        # 2번의 에포크 동안 성능 향상이 없으면 중단\n",
    "    early_stopping_threshold=0.0,     # 성능 향상으로 간주할 최소 차이값\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 과정을 시각화하기 위한 callback을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class VisualizationCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.eval_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.eval_accuracies = []\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        # 데이터만 저장하고 시각화는 하지 않음\n",
    "        if state.epoch is not None:\n",
    "            self.eval_losses.append(metrics.get('eval_loss', 0))\n",
    "            self.eval_accuracies.append(metrics.get('eval_accuracy', 0))\n",
    "            \n",
    "            if len(state.log_history) > 0:\n",
    "                for entry in reversed(state.log_history):\n",
    "                    if 'loss' in entry and 'epoch' in entry and entry['epoch'] == state.epoch:\n",
    "                        self.train_losses.append(entry['loss'])\n",
    "                        break\n",
    "                \n",
    "                for entry in reversed(state.log_history):\n",
    "                    if 'train_accuracy' in entry and 'epoch' in entry and entry['epoch'] == state.epoch:\n",
    "                        self.train_accuracies.append(entry['train_accuracy'])\n",
    "                        break\n",
    "\n",
    "    def plot_progress(self):\n",
    "        clear_output(wait=True)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss 그래프\n",
    "        ax1.plot(self.train_losses, label='Train Loss', marker='o')\n",
    "        ax1.plot(self.eval_losses, label='Validation Loss', marker='o')\n",
    "        ax1.set_title('Training and Validation Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Accuracy 그래프\n",
    "        ax2.plot(self.train_accuracies, label='Train Accuracy', marker='o')\n",
    "        ax2.plot(self.eval_accuracies, label='Validation Accuracy', marker='o')\n",
    "        ax2.set_title('Training and Validation Accuracy')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Trainer 설정 업데이트\n",
    "visualization_callback = VisualizationCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터에 따른 변화를 비교하기 위해 학습 함수를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인 (CUDA와 MPS 모두 체크)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "def model_experiments(learning_rate, batch_size):\n",
    "    # 실험 결과를 저장할 딕셔너리\n",
    "    experiment_name = f\"lr: {learning_rate} batch_size: {batch_size}\"\n",
    "    \n",
    "    # TrainingArguments 설정\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{experiment_name}\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=50,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_accuracy\",\n",
    "        save_total_limit=1,\n",
    "        logging_strategy=\"epoch\",\n",
    "        logging_dir=f\"./logs_{experiment_name}\"\n",
    "    )\n",
    "    \n",
    "    # 모델 초기화\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        'roberta-base',\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "    \n",
    "    # RoBERTa 동결\n",
    "    for param in model.roberta.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 시각화 콜백 초기화\n",
    "    visualization_callback = VisualizationCallback()\n",
    "\n",
    "    # Trainer 설정\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=validation_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[early_stopping_callback, visualization_callback]\n",
    "    )\n",
    "    \n",
    "    # 학습\n",
    "    trainer.train()\n",
    "    \n",
    "    # 평가\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # 테스트 세트 평가\n",
    "    test_matched_results = trainer.evaluate(\n",
    "        eval_dataset=tokenized_test_matched,\n",
    "        metric_key_prefix=\"test_matched\"\n",
    "    )\n",
    "    test_mismatched_results = trainer.evaluate(\n",
    "        eval_dataset=tokenized_test_mismatched,\n",
    "        metric_key_prefix=\"test_mismatched\"\n",
    "    )\n",
    "    \n",
    "    # 결과 저장\n",
    "    results = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size,\n",
    "        'eval_results': eval_results,\n",
    "        'test_matched_results': test_matched_results,\n",
    "        'test_mismatched_results': test_mismatched_results,       \n",
    "        'train_losses': visualization_callback.train_losses,\n",
    "        'eval_losses': visualization_callback.eval_losses,\n",
    "        'train_accuracies': visualization_callback.train_accuracies,\n",
    "        'eval_accuracies': visualization_callback.eval_accuracies,\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습율과 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "실험 시작: learning_rate=0.001, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4912' max='61400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4912/61400 07:13 < 1:23:05, 11.33 it/s, Epoch 4/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.116700</td>\n",
       "      <td>1.067155</td>\n",
       "      <td>0.410204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.081000</td>\n",
       "      <td>1.035699</td>\n",
       "      <td>0.497959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.071300</td>\n",
       "      <td>1.011063</td>\n",
       "      <td>0.479592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.064900</td>\n",
       "      <td>1.024491</td>\n",
       "      <td>0.463265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='668' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_accuracy so early stopping is disabled\n"
     ]
    }
   ],
   "source": [
    "# 실험 실행\n",
    "results = []\n",
    "learning_rates = [1e-3, 2e-5]\n",
    "batch_size_list = [16, 32]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_size_list:\n",
    "        print(f\"\\n실험 시작: learning_rate={lr}, batch_size={batch_size}\")\n",
    "        result = model_experiments(lr, batch_size)\n",
    "        results.append(result)\n",
    "\n",
    "# 결과 시각화\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Loss 비교\n",
    "plt.subplot(1, 2, 1)\n",
    "for result in results:\n",
    "    label = f\"LR={result['learning_rate']}, BatchSize={result['batch_size']}\"\n",
    "    plt.plot(result['train_losses'], label=f'{label} (Train)')\n",
    "    plt.plot(result['eval_losses'], label=f'{label} (Val)', linestyle='--')\n",
    "plt.title('Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy 비교\n",
    "plt.subplot(1, 2, 2)\n",
    "for result in results:\n",
    "    label = f\"LR={result['learning_rate']}, BatchSize={result['batch_size']}\"\n",
    "    plt.plot(result['train_accuracies'], label=f'{label} (Train)')\n",
    "    plt.plot(result['eval_accuracies'], label=f'{label} (Val)', linestyle='--')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(\"\\n=== 실험 결과 요약 ===\")\n",
    "for result in results:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"\\nLearning Rate: {result['learning_rate']}\")\n",
    "    print(f\"Batch Size: {result['batch_size']}\")\n",
    "    \n",
    "    print(\"\\n검증 결과:\")\n",
    "    for metric, value in result['validation_results'].items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Test Matched 결과 ===\")\n",
    "    for metric, value in result['test_matched_results'].items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Test Mismatched 결과 ===\")\n",
    "    for metric, value in result['test_mismatched_results'].items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # 정확도 비교\n",
    "    val_acc = result['validation_results'].get('eval_accuracy', 0)\n",
    "    test_matched_acc = result['test_matched_results'].get('test_matched_accuracy', 0)\n",
    "    test_mismatched_acc = result['test_mismatched_results'].get('test_mismatched_accuracy', 0)\n",
    "    \n",
    "    print(f\"\\n정확도 비교:\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Test Matched Accuracy: {test_matched_acc:.4f}\")\n",
    "    print(f\"Test Mismatched Accuracy: {test_mismatched_acc:.4f}\")\n",
    "    print(f\"Matched vs Mismatched 차이: {test_matched_acc - test_mismatched_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "welcomedl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
