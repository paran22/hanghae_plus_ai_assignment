{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5주차] 심화과제 - 다양한 형태의 입력을 가지는 LLM 서비스 개발"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.3.23)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (1.75.0)\n",
      "Requirement already satisfied: chromadb in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.6.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (0.3.54)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (0.3.32)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.115.12)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (2.2.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (3.25.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.21.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.32.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (3.10.16)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.46.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.39.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv langchain openai chromadb pandas sentence-transformers matplotlib transformers accelerate torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 선정\n",
    "\n",
    "데이터는 공공API에서 제공하는 [국립중앙도서관 사서추천도서목록](https://www.nl.go.kr/NL/contents/N31101030900.do)을 사용한다.\n",
    "\n",
    "xml 데이터를 json 데이터로 변환하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "📚 데이터 구조\n",
      "==================================================\n",
      "\n",
      "📍 데이터 키 목록:\n",
      "category_code, category_name, title, author, publisher, isbn, contents, table_of_contents, publish_year, recommend_year, recommend_month\n",
      "\n",
      "📍 첫 번째 도서 상세 정보:\n",
      "\n",
      "category_code:\n",
      "    6\n",
      "\n",
      "category_name:\n",
      "    인문과학\n",
      "\n",
      "title:\n",
      "    제대로 연습하는 법 : 어학부터 스포츠까지, 인지심리학이 제시하는 배움의 기술\n",
      "\n",
      "author:\n",
      "    아투로 E. 허낸데즈 지음 ;방진이 옮김\n",
      "\n",
      "publisher:\n",
      "    북트리거 지학사\n",
      "\n",
      "isbn:\n",
      "    9791193378335\n",
      "\n",
      "contents:\n",
      "    한때 유행했던 일만 시간의 법칙을 기억하는가? 어떤 분야에서 전문가가 되려면 최소한 일만 시간의 훈련이 필요하다는 개념이다. 하지만 단순히 연습의 양이 많다고 해서 모두가 전문가가\n",
      " 되는 것은 아니다. 이 책은 심리학자이자 다중언어 구사자, 테니스 선수로도 활약했던 저자가 학습과 훈련, 그리고 기량 향상의 상관관계를 연구한 결과를 담고 있다. 장 피아제, 노\n",
      "엄 촘스키, 그리고 일만 시간의 법칙을 제창한 심리학자 안데르스 에릭손 등 대가들의 이론 및 최신 연구 결과를 바탕으로, 뇌과학과 인지심리학적 관점에서 '제대로 연습하는 법'을 탐\n",
      "구한다. 아마추어 스포츠 선수, 유명 체스 선수, 다중언어 구사자, 피아노 연주자 등 다양한 사례 분석을 통해 연습의 물리적 양보다 중요한 것은 질적인 측면임을 강조한다. 적절한 \n",
      "휴식 속에서 배운 것을 재조합하고, 몰입 상태에서 연습할 때 비로소 '최고'라는 목표에 도달할 수 있는 것이다. 벌써 2025년이 100일 넘게 흘렀다. 완연한 봄을 맞이하여 새로\n",
      "운 기술을 배우고 싶거나, 그동안 노력에 비해 실력이 늘지 않는다고 느껴왔다면, 이 책을 길잡이 삼아 ‘제대로 연습하는 법’을 배워보면 어떨까?\n",
      "\n",
      "table_of_contents:\n",
      "    서론 : 작은 조각들을 재조합하는 인간 = 7 01장 '제대로' 연습하기 = 17 02장 댄 계획과 성인기 이후의 숙달 : 사례연구 1 = 41 03장 인간의 삶과 창발성 = 53\n",
      " 04장 창발적 기능으로서의 테니스 서브 : 사례연구 2 = 77 05장 아동기, 청소년기의 발달 과정 = 95 06장 톰 바이어와 작은 공 요법 : 사례연구 3 = 113 07장\n",
      " 읽고 인식한다는 것, 그 가능성 = 129 08장 구달과 뉴섬의 감각운동적 해결책 : 사례연구 4 = 157 09장 성인기 이후 언어 습득의 고행길 = 167 10장 바티와 테니\n",
      "스, 그리고 크리켓 : 사례연구 5 = 197 11장 유전자는 혼자서 일하지 않는다 = 213 12장 일란성쌍둥이는 결코 똑같지 않다 : 사례연구 6 = 245 13장 우리 안의 \n",
      "두 자아 = 255 14장 '고령' 운동선수와 환경의 변화 : 사례연구 7 = 277 15장 진화와 혁명, 그리고 숙달 = 291 16장 돈 메모의 가르침, 창발과 향상 : 사례연\n",
      "구 8 = 307 결론 : 숙달의 다섯 가지 원칙 = 317 참고 문헌 = 331 도판 출처 = 344 찾아보기 = 345\n",
      "\n",
      "publish_year:\n",
      "    2024\n",
      "\n",
      "recommend_year:\n",
      "    2025\n",
      "\n",
      "recommend_month:\n",
      "    4\n",
      "\n",
      "==================================================\n",
      "📚 전체 도서 수: 1388권\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON 데이터 로드\n",
    "with open('library_books.json', 'r', encoding='utf-8') as f:\n",
    "    books = json.load(f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📚 데이터 구조\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\n📍 데이터 키 목록:\")\n",
    "print(\", \".join(list(books[0].keys())))\n",
    "\n",
    "print(\"\\n📍 첫 번째 도서 상세 정보:\")\n",
    "for key, value in books[0].items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    # 긴 텍스트는 줄바꿈하여 보기 좋게 출력\n",
    "    if len(str(value)) > 100:\n",
    "        # 100자마다 줄바꿈\n",
    "        formatted_value = '\\n'.join([str(value)[i:i+100] for i in range(0, len(str(value)), 100)])\n",
    "        print(f\"    {formatted_value}\")\n",
    "    else:\n",
    "        print(f\"    {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"📚 전체 도서 수: {len(books)}권\")\n",
    "print(\"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "category 정보를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 총 분류 수: 6개\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b3029 th {\n",
       "  text-align: center;\n",
       "  background-color: #f0f0f0;\n",
       "}\n",
       "#T_b3029 td {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_b3029_row0_col0, #T_b3029_row0_col1, #T_b3029_row0_col2, #T_b3029_row1_col0, #T_b3029_row1_col1, #T_b3029_row1_col2, #T_b3029_row2_col0, #T_b3029_row2_col1, #T_b3029_row2_col2, #T_b3029_row3_col0, #T_b3029_row3_col1, #T_b3029_row3_col2, #T_b3029_row4_col0, #T_b3029_row4_col1, #T_b3029_row4_col2, #T_b3029_row5_col0, #T_b3029_row5_col1, #T_b3029_row5_col2 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b3029\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b3029_level0_col0\" class=\"col_heading level0 col0\" >분류 코드</th>\n",
       "      <th id=\"T_b3029_level0_col1\" class=\"col_heading level0 col1\" >분류명</th>\n",
       "      <th id=\"T_b3029_level0_col2\" class=\"col_heading level0 col2\" >도서 수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b3029_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b3029_row0_col0\" class=\"data row0 col0\" >6</td>\n",
       "      <td id=\"T_b3029_row0_col1\" class=\"data row0 col1\" >인문과학</td>\n",
       "      <td id=\"T_b3029_row0_col2\" class=\"data row0 col2\" >342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3029_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b3029_row1_col0\" class=\"data row1 col0\" >5</td>\n",
       "      <td id=\"T_b3029_row1_col1\" class=\"data row1 col1\" >사회과학</td>\n",
       "      <td id=\"T_b3029_row1_col2\" class=\"data row1 col2\" >338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3029_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_b3029_row2_col0\" class=\"data row2 col0\" >4</td>\n",
       "      <td id=\"T_b3029_row2_col1\" class=\"data row2 col1\" >자연과학</td>\n",
       "      <td id=\"T_b3029_row2_col2\" class=\"data row2 col2\" >319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3029_level0_row3\" class=\"row_heading level0 row3\" >2</th>\n",
       "      <td id=\"T_b3029_row3_col0\" class=\"data row3 col0\" >11</td>\n",
       "      <td id=\"T_b3029_row3_col1\" class=\"data row3 col1\" >어문학</td>\n",
       "      <td id=\"T_b3029_row3_col2\" class=\"data row3 col2\" >296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3029_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b3029_row4_col0\" class=\"data row4 col0\" >425</td>\n",
       "      <td id=\"T_b3029_row4_col1\" class=\"data row4 col1\" ></td>\n",
       "      <td id=\"T_b3029_row4_col2\" class=\"data row4 col2\" >92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3029_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b3029_row5_col0\" class=\"data row5 col0\" >8</td>\n",
       "      <td id=\"T_b3029_row5_col1\" class=\"data row5 col1\" ></td>\n",
       "      <td id=\"T_b3029_row5_col2\" class=\"data row5 col2\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12380d7c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 카테고리 코드와 이름을 매핑하여 저장\n",
    "category_map = defaultdict(int)\n",
    "for book in books:\n",
    "    category_key = (book['category_code'], book['category_name'])\n",
    "    category_map[category_key] += 1\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "df_categories = pd.DataFrame([\n",
    "    {\n",
    "        '분류 코드': code,\n",
    "        '분류명': name,\n",
    "        '도서 수': count\n",
    "    }\n",
    "    for (code, name), count in category_map.items()\n",
    "])\n",
    "\n",
    "# 도서 수를 기준으로 내림차순 정렬\n",
    "df_categories = df_categories.sort_values('도서 수', ascending=False)\n",
    "\n",
    "# 스타일 적용\n",
    "styled_df = df_categories.style\\\n",
    "    .set_properties(**{'text-align': 'center'})\\\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [('text-align', 'center'), ('background-color', '#f0f0f0')]},\n",
    "        {'selector': 'td', 'props': [('text-align', 'center')]},\n",
    "    ])\\\n",
    "    .format({'도서 수': '{:,d}'})  # 천 단위 구분자 추가\n",
    "\n",
    "# 테이블 출력\n",
    "print(f\"\\n📚 총 분류 수: {len(df_categories)}개\\n\")\n",
    "display(styled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chuck size를 설정하기 위해 텍스트 길이를 파악했다.\n",
    "\n",
    "임베딩할 데이터는 category_name, title, contents, table_of_contents이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 각 필드별 텍스트 길이 통계 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>카테고리</th>\n",
       "      <th>제목</th>\n",
       "      <th>내용</th>\n",
       "      <th>목차</th>\n",
       "      <th>전체</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>135.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>323.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>861.00</td>\n",
       "      <td>6677.00</td>\n",
       "      <td>7296.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.52</td>\n",
       "      <td>14.16</td>\n",
       "      <td>495.10</td>\n",
       "      <td>884.01</td>\n",
       "      <td>1417.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>4.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>490.00</td>\n",
       "      <td>734.50</td>\n",
       "      <td>1264.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.03</td>\n",
       "      <td>9.65</td>\n",
       "      <td>95.41</td>\n",
       "      <td>740.71</td>\n",
       "      <td>746.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        카테고리     제목      내용       목차       전체\n",
       "min     0.00   1.00  135.00     0.00   323.00\n",
       "max     4.00  75.00  861.00  6677.00  7296.00\n",
       "mean    3.52  14.16  495.10   884.01  1417.79\n",
       "median  4.00  11.00  490.00   734.50  1264.50\n",
       "std     1.03   9.65   95.41   740.71   746.49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 전체 텍스트 길이 백분위수 ===\n",
      "25번째 백분위: 881자\n",
      "50번째 백분위: 1264자\n",
      "75번째 백분위: 1758자\n",
      "90번째 백분위: 2343자\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 각 도서별 텍스트 길이 계산\n",
    "text_lengths = []\n",
    "for book in books:\n",
    "    text = f\"카테고리: {book['category_name']}\\n제목: {book['title']}\\n내용: {book['contents']}\\n목차: {book['table_of_contents']}\"\n",
    "    length_info = {\n",
    "        '카테고리': len(book['category_name']),\n",
    "        '제목': len(book['title']),\n",
    "        '내용': len(book['contents']),\n",
    "        '목차': len(book['table_of_contents']),\n",
    "        '전체': len(text)\n",
    "    }\n",
    "    text_lengths.append(length_info)\n",
    "\n",
    "# DataFrame으로 변환\n",
    "df_lengths = pd.DataFrame(text_lengths)\n",
    "\n",
    "# 기본 통계 계산\n",
    "stats = df_lengths.agg(['min', 'max', 'mean', 'median', 'std']).round(2)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n=== 각 필드별 텍스트 길이 통계 ===\")\n",
    "display(stats)\n",
    "\n",
    "# 백분위수 계산\n",
    "percentiles = df_lengths['전체'].quantile([0.25, 0.5, 0.75, 0.9])\n",
    "print(\"\\n=== 전체 텍스트 길이 백분위수 ===\")\n",
    "for p, v in percentiles.items():\n",
    "    print(f\"{int(p*100)}번째 백분위: {int(v)}자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 백터 DB 생성\n",
    "\n",
    "벡터 DB를 생성한다.\n",
    "\n",
    "chuck size는 중앙값과 75% 사이의 값으로 설정하고, chunk overlap은 chunk size의 20% 정도로 설정한다.\n",
    "\n",
    "임베딩 모델로는 무료로 사용할 수 있는 sentence-transformers의 다국어 지원 모델을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sm/f3jq7h1d5ms4gybg0zfs83fm0000gn/T/ipykernel_62894/3239963243.py:20: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인 및 디바이스 설정\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    device_map = {'': 0}  # 단일 GPU 사용\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    device_map = {'': device}  # Apple Silicon GPU\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    device_map = {'': device}\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': device}\n",
    ")\n",
    "\n",
    "# 텍스트 스플리터 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,        # 중앙값과 75퍼센타일 사이의 값으로 설정\n",
    "    chunk_overlap=300,      # chunk_size의 20% 정도로 설정\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # 문장 단위로 끊기도록 \". \" 추가\n",
    ")\n",
    "\n",
    "# 임베딩할 텍스트 준비 및 메타데이터 포함\n",
    "documents = []\n",
    "for book in books:\n",
    "    text = f\"카테고리: {book['category_name']}\\n제목: {book['title']}\\n내용: {book['contents']}\\n목차: {book['table_of_contents']}\"\n",
    "    \n",
    "    # 메타데이터 준비\n",
    "    metadata = {\n",
    "        'title': book['title'],\n",
    "        'category': book['category_name'],\n",
    "        'author': book['author'],\n",
    "        'isbn': book['isbn']\n",
    "    }\n",
    "    \n",
    "    # 텍스트 분할 및 메타데이터 추가\n",
    "    chunks = text_splitter.create_documents(\n",
    "        texts=[text],\n",
    "        metadatas=[metadata]\n",
    "    )\n",
    "    documents.extend(chunks)\n",
    "\n",
    "# 벡터 DB 생성\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 공통 설정\n",
    "\n",
    "프롬프트에 기본으로 사용할 템플릿을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"다음은 검색된 도서 정보들입니다:\n",
    "\n",
    "{context}\n",
    "\n",
    "이 정보들을 바탕으로 다음 질문에 답변해주세요: {question}\n",
    "\n",
    "답변 작성 가이드:\n",
    "1. 제시된 도서들의 난이도, 내용, 특징을 비교 분석해주세요.\n",
    "2. 질문자의 요구사항에 가장 적합한 도서를 선정해주세요.\n",
    "3. 선정한 도서가 첫 번째로 제시된 도서가 아니더라도 괜찮습니다.\n",
    "\n",
    "답변은 한국어로 작성해주시고, 추천하는 도서의 제목과 저자를 반드시 포함해주세요.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백터 db에서 유사도 상위 몇 개를 선정할지 개수를 선언한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델1. Open LLM\n",
    "\n",
    "모델은 HuggingFace에서 제공하는 open LLM인 Bllossom/llama-3.2-Korean-Bllossom-3B를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235d8a17ff8844a798aba875e93200f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_id = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map\n",
    ")\n",
    "\n",
    "# pad_token 설정\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# 모델에도 pad_token_id 설정\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorstore의 similarity_search를 사용하여 백터 데이터베이스에서 의미적 유사도 검색을 수행한다.\n",
    "\n",
    "similarity_search는 입력된 질문을 동일한 임베딩 모델로 벡터화하고, 백터 db에 저장된 모든 문서 백터들과 코사인 유사도를 계산하여 가장 유사도가 높은 k개의 문서를 반환한다.\n",
    "\n",
    "다음과 같이 메타데이터 기반 필터링도 가능하다.\n",
    "\n",
    "```python\n",
    "filtered_docs = vectorstore.similarity_search(\n",
    "    \"인공지능 입문서\",\n",
    "    k=3,\n",
    "    filter={\"category\": \"자연과학\"}\n",
    ")\n",
    "```\n",
    "\n",
    "그리고 open LLM 모델을 사용해 추천 이유에 대한 텍스트를 생성하여 응답한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "def get_book_recommendation(question: str):\n",
    "    # 관련 문서 검색\n",
    "    docs = vectorstore.similarity_search(question, k=top_k)\n",
    "    \n",
    "    # 검색된 문서들의 내용을 하나의 문자열로 결합\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"제목: {doc.metadata['title']}\\n\"\n",
    "        f\"저자: {doc.metadata['author']}\\n\"\n",
    "        f\"카테고리: {doc.metadata['category']}\\n\"\n",
    "        f\"내용: {doc.page_content}\"\n",
    "        for doc in docs\n",
    "    ])\n",
    "    \n",
    "    # 프롬프트 생성\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt.format(context=context, question=question)}\n",
    "    ]\n",
    "    \n",
    "    # 입력 인코딩 및 attention mask 생성\n",
    "    encoded = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = encoded.to(model.device)\n",
    "    attention_mask = torch.ones_like(input_ids).to(model.device)\n",
    "    \n",
    "    # pad_token_id 설정\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    # 종료 토큰 설정\n",
    "    terminators = [\n",
    "        tokenizer.convert_tokens_to_ids(\"<|end_of_text|>\"),\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    # pad_token_id가 설정되어 있는지 확인하고 설정\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        model.config.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    # 응답 생성\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=1024,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=terminators,\n",
    "        # True: 확률적 샘플링 사용 (더 창의적인 응답)\n",
    "        # False: 최대 확률 토큰 선택 (더 일관적인 응답)\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        # 누적 확률이 이 값을 넘는 토큰들만 고려\n",
    "        # 높을수록 더 다양한 선택지 고려\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(\n",
    "        # 응답에는 입력(프롬프트)와 새로 생성된 결과가 모두 포함되어 있음\n",
    "        # 입력 프롬프트를 제외하고 새로 생성된 부분만 출력\n",
    "        outputs[0][input_ids.shape[-1]:], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response,\n",
    "        \"similar_books\": [\n",
    "            {\n",
    "                \"title\": doc.metadata[\"title\"],\n",
    "                \"author\": doc.metadata[\"author\"],\n",
    "                \"category\": doc.metadata[\"category\"]\n",
    "            }\n",
    "            for doc in docs\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "답변을 출력하기 위한 함수를 선언한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_long_text(text: str, width: int = 80):\n",
    "    \"\"\"긴 텍스트를 지정된 너비로 줄바꿈하여 반환\"\"\"\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    current_line = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for word in words:\n",
    "        word_length = len(word)\n",
    "        if current_length + word_length + 1 <= width:\n",
    "            current_line.append(word)\n",
    "            current_length += word_length + 1\n",
    "        else:\n",
    "            lines.append(' '.join(current_line))\n",
    "            current_line = [word]\n",
    "            current_length = word_length + 1\n",
    "    \n",
    "    if current_line:\n",
    "        lines.append(' '.join(current_line))\n",
    "    \n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def print_recommendation_result(result, question):\n",
    "    \"\"\"추천 결과를 포맷팅하여 출력\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📚 도서 추천 결과\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n💭 질문:\")\n",
    "    print(f\"{question}\")\n",
    "    \n",
    "    print(\"\\n📝 답변:\")\n",
    "    formatted_answer = format_long_text(result['answer'])\n",
    "    print(f\"{formatted_answer}\")\n",
    "    \n",
    "    print(f\"\\n📚 검색된 유사 도서 (상위 {top_k}개):\")\n",
    "    for idx, book in enumerate(result['similar_books'], 1):\n",
    "        print(f\"\\n{idx}. 제목: {book['title']}\")\n",
    "        print(f\"   저자: {book['author']}\")\n",
    "        print(f\"   카테고리: {book['category']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문을 추가해 모델을 테스트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시\n",
    "question = \"인공지능 입문서 추천해주세요\"\n",
    "result = get_book_recommendation(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "답변을 출력한다.\n",
    "\n",
    "open LLM 모델은 프롬프트로 같이 입력한 책에 대한 정보를 문장 그대로 가져와서 사용하는 경우가 많았다.\n",
    "\n",
    "응답도 오래걸렸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📚 도서 추천 결과\n",
      "================================================================================\n",
      "\n",
      "💭 질문:\n",
      "인공지능 입문서 추천해주세요\n",
      "\n",
      "📝 답변:\n",
      "인공지능 입문서 추천을 위해 제시된 도서들의 내용을 비교 분석해보겠습니다. 1. **제목: 내 정원의 로봇** - **저자: 데보라 인스톨**\n",
      "- **난이도 및 내용**: 이 책은 인공지능 소재에 작가의 상상력을 더해 풀어낸 따뜻한 소설입니다. 인공지능 하인이 집안일을 돕고,\n",
      "안드로이드가 운전을 하는 미래 영국의 어느 마을에 사는 주인공을 중심으로 이야기가 전개됩니다. - **특징**: 인공지능의 다양한 성공 사례와\n",
      "주인공의 성장 과정을 통해 인공지능의 가능성을 시사합니다. 주인공 벤은 낡고 고장난 로봇 '탱'을 고치기 위해 여행을 떠나고, 그 과정에서\n",
      "둘은 다양한 사건을 겪으며 서로를 위로하고 성장합니다. 2. **제목: 앙코르 내 인생** - **저자: 신동흔, 김수혜, 김미리, 김신영**\n",
      "- **난이도 및 내용**: 이 책은 14명의 주인공이 다양한 직업과 삶을 통해 성장하고 성숙하는 과정을 다룹니다. 각 주인공이 자신의 삶의\n",
      "고장을 해결하고 성장하는 이야기를 통해 인공지능과 관련된 주제를 다룹니다. - **특징**: 다양한 직업과 삶의 경험을 통해 인공지능의\n",
      "가능성을 시사하며, 주인공들이 성장하고 성숙하는 과정을 통해 인공지능에 대한 공감을 유도합니다. 3. **제목: 천개의 파랑** - **저자:\n",
      "천선란** - **난이도 및 내용**: 이 책은 2035년을 배경으로 한 SF소설입니다. 인간과 로봇, 경주마가 함께 주인공을 이루며 다양한\n",
      "이야기를 전개합니다. - **특징**: 과학기술의 발전으로 인해 소외된 인간과 동물, 로봇에 대해 이야기하며, 주인공들의 서로를 위한 서투른\n",
      "배려와 성장 과정을 통해 인공지능에 대한 공감을 유도합니다. 이러한 도서들의 특징과 내용을 비교하면, **내 정원의 로봇**은 인공지능의\n",
      "다양한 성공 사례와 주인공의 성장 과정을 통해 인공지능의 가능성을 시사하는 소설입니다. 반면, **앙코르 내 인생**은 다양한 직업과 삶의\n",
      "경험을 통해 인공지능의 가능성을 시사하며, 주인공들이 성장하고 성숙하는 과정을 통해 인공지능에 대한 공감을 유도하는 책입니다. **천개의\n",
      "파랑**은 SF소설로 인공지능과 관련된 주제를 다룹니다. 이러한 특징을 고려하면, 인공지능 입문서로 가장 적합한 도서는 **내 정원의\n",
      "로봇**입니다. 이 책은 인공지능의 다양한 성공 사례와 주인공의 성장 과정을 통해 인공지능의 가능성을 시사하며, 주인공의 감정과 성장 과정을\n",
      "통해 인공지능에 대한 공감을 유도합니다. 따라서, **내 정원의 로봇**이 제시된 도서들 중 가장 적합한 인공지능 입문서로 추천합니다.\n",
      "\n",
      "📚 검색된 유사 도서 (상위 3개):\n",
      "\n",
      "1. 제목: 내 정원의 로봇\n",
      "   저자: 데보라 인스톨\n",
      "   카테고리: 어문학\n",
      "\n",
      "2. 제목: 앙코르 내 인생\n",
      "   저자: 신동흔, 김수혜, 김미리, 김신영\n",
      "   카테고리: 어문학\n",
      "\n",
      "3. 제목: 천개의 파랑\n",
      "   저자: 천선란\n",
      "   카테고리: 어문학\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print_recommendation_result(result, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"재미있는 소설 추천해줘\"와 같은 추상적인 질문에도 답변하였지만, 벡터db에서 유사도로 추천된 도서 리스트가 아쉬웠다.\n",
    "\n",
    "추천된 도서 리스트 중에는 비교적 질문과 가까운 도서를 추천하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"재미있는 소설 추천해줘\"\n",
    "result = get_book_recommendation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📚 도서 추천 결과\n",
      "================================================================================\n",
      "\n",
      "💭 질문:\n",
      "재미있는 소설 추천해줘\n",
      "\n",
      "📝 답변:\n",
      "제시된 도서들의 난이도, 내용, 특징을 비교 분석해보고, 질문자의 요구사항에 가장 적합한 도서를 선정해보겠습니다. 1. 제시된 도서들의\n",
      "난이도와 내용을 분석하면 다음과 같습니다: - **옛그림 속 양반의 한평생**: 이 책은 조선시대 양반의 일상 생활을 그린 소설입니다.\n",
      "조선시대에 살았던 평범한 양반들의 일상과 삶을 통해 조선시대 사회의 특성을 이해할 수 있는 작품입니다. 책의 내용은 단순한 일상 이야기보다는\n",
      "조선시대 양반들의 삶을 깊이 있게 설명하고 있습니다. - **그 무렵 누군가**: 이 책은 히가시노 게이고 작가의 단편 소설을 모아 한 권으로\n",
      "엮은 책입니다. 히가시노 작가의 작품은 극적 재미와 예리한 비판적 의식을 가지고 있으며, 이 책에서는 다양한 주제와 다채로운 소재를 다루고\n",
      "있습니다. - **도시를 걷는 시간**: 이 책은 서울 시내 표석을 통해 조선시대와 현재의 차이를 비교하며 역사와 문화를 탐구한 작품입니다.\n",
      "작가는 조선시대와 현재의 주변에 위치한 표석을 통해 시간의 길을 거슬러 역사를 단순히 과거로 치부할 것이 아닌 어제와 오늘 그리고 내일을\n",
      "만나는 순간임을 깨닫고자 합니다. 2. 질문자의 요구사항을 분석해보고, 가장 적합한 도서를 선정해보겠습니다. - 질문자는 재미있는 소설을\n",
      "추천해주고자 합니다. 이 경우, **그 무렵 누군가**와 **도시를 걷는 시간**이 모두 재미있는 소설이 될 수 있지만, 질문자가 단순히\n",
      "재미있는 소설을 찾는 것이라면, **그 무렵 누군가**가 더 적합할 수 있습니다. 이 책은 히가시노 게이고 작가의 작품을 통해 다양한 주제와\n",
      "소재를 다루고 있으며, 극적 재미와 예리한 비판적 의식을 가지고 있어 독자들에게 큰 호기심을 자극할 수 있습니다. 3. 선정한 도서의 제목과\n",
      "저자는 다음과 같습니다: - **그 무렵 누군가**: 히가시노 게이고 저자 이 책은 히가시노 게이고 작가의 작품을 통해 다양한 주제와 소재를\n",
      "다루고 있으며, 극적 재미와 예리한 비판적 의식을 가지고 있어 독자들에게 큰 호기심을 자극할 수 있습니다. 따라서, 질문자의 요구사항에 가장\n",
      "적합한 도서로 **그 무렵 누군가**를 추천해드릴 수 있습니다.\n",
      "\n",
      "📚 검색된 유사 도서 (상위 3개):\n",
      "\n",
      "1. 제목: 옛그림 속 양반의 한평생\n",
      "   저자: 허인욱\n",
      "   카테고리: 인문과학\n",
      "\n",
      "2. 제목: 그 무렵 누군가\n",
      "   저자: 히가시노 게이고 \n",
      "   카테고리: 어문학\n",
      "\n",
      "3. 제목: 도시를 걷는 시간\n",
      "   저자: 김별아\n",
      "   카테고리: 어문학\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print_recommendation_result(result, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델2: GPT\n",
    "gpt 모델로는 gpt-4o-mini를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API KEY를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델은 gpt-4o-mini를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,          # 적당한 창의성\n",
    "    top_p=0.9,               # 다양한 선택 허용\n",
    "    max_tokens=512,          # 적당한 길이\n",
    "    presence_penalty=0.2,    # 약간의 새로운 관점 도입\n",
    "    frequency_penalty=0.3,   # 반복 방지\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "def get_book_recommendation_from_gpt(question: str):\n",
    "    # 관련 문서 검색\n",
    "    docs = vectorstore.similarity_search(question, k=top_k)\n",
    "    \n",
    "    # 검색된 문서들의 내용을 하나의 문자열로 결합\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"제목: {doc.metadata['title']}\\n\"\n",
    "        f\"저자: {doc.metadata['author']}\\n\"\n",
    "        f\"카테고리: {doc.metadata['category']}\\n\"\n",
    "        f\"내용: {doc.contents}\"\n",
    "        for doc in docs\n",
    "    ])\n",
    "    \n",
    "    # 프롬프트 생성\n",
    "    formatted_prompt = prompt.format(\n",
    "        context=context,\n",
    "        question=question\n",
    "    )\n",
    "    \n",
    "    # LLM에 질의\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response.content,\n",
    "        \"similar_books\": [\n",
    "            {\n",
    "                \"title\": doc.metadata[\"title\"],\n",
    "                \"author\": doc.metadata[\"author\"],\n",
    "                \"category\": doc.metadata[\"category\"]\n",
    "            }\n",
    "            for doc in docs\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시\n",
    "question = \"인공지능 입문서 추천해주세요\"\n",
    "result = get_book_recommendation_from_gpt(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 출력한다.\n",
    "\n",
    "open LLM에 비해 input으로 넣은 도서 정보 문장을 그대로 가져오기 보다는 요약을 하고 있고, 질문에 적합한지에 대해서도 더 추론하여 답변한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📚 도서 추천 결과\n",
      "================================================================================\n",
      "\n",
      "💭 질문:\n",
      "인공지능 입문서 추천해주세요\n",
      "\n",
      "📝 답변:\n",
      "제시된 도서 정보들을 바탕으로 인공지능 입문서를 추천해 드리겠습니다. 1. **도서 비교 분석**: - **내 정원의 로봇 (저자: 데보라\n",
      "인스톨)**: 이 책은 인공지능을 소재로 한 소설로, 주인공 벤이 고장 난 로봇 탱을 수리하며 겪는 성장 이야기를 다룹니다. 인공지능의 발전과\n",
      "인간의 감정을 연결지어 따뜻한 이야기로 풀어내고 있어, 인공지능 기술에 대한 직접적인 설명보다는 그로 인해 변화하는 인간 관계와 정서를\n",
      "중심으로 하고 있습니다. - **앙코르 내 인생 (저자: 신동흔 외)**: 이 책은 다양한 사람들의 인생 이야기를 통해 새로운 삶의 전환점을\n",
      "탐구하는 에세이집입니다. 주제는 삶의 변화와 도전이지만, 인공지능 관련 내용은 포함되어 있지 않습니다. - **천개의 파랑 (저자:\n",
      "천선란)**: 이 SF 소설은 2035년의 미래를 배경으로 하며, 경주마와 로봇 기수 간의 관계를 통해 인간과 동물, 로봇에 대한 사회적\n",
      "이슈를 다루고 있습니다. 역시 인공지능에 대한 기술적 설명보다는 감정적인 서사와 사회적 메시지를 중심으로 전개됩니다. 2. **요구사항에\n",
      "적합한 도서 선정**: - 제시된 도서들 중에서 인공지능에 대한 깊이 있는 이해를 원하는 입문서로는 적합하지 않습니다. 하지만, '내 정원의\n",
      "로봇'은 인공지능과 관련된 주제를 다루고 있으며, 이를 통해 독자는 인공지능의 적용 가능성과 인간과의 상호작용을 간접적으로 경험할 수\n",
      "있습니다. 3. **추천 도서**: - 따라서 인공지능 입문서로는 **‘내 정원의 로봇’ (저자: 데보라 인스톨)**을 추천드립니다. 이 책은\n",
      "소설 형식으로 이야기되기 때문에 부담 없이 읽을 수 있으며, 현대 사회에서의 인공지능에 대한 다양한 시각을 제공받을 수 있습니다. 읽으시는 데\n",
      "도움이 되길 바랍니다!\n",
      "\n",
      "📚 검색된 유사 도서 (상위 3개):\n",
      "\n",
      "1. 제목: 내 정원의 로봇\n",
      "   저자: 데보라 인스톨\n",
      "   카테고리: 어문학\n",
      "\n",
      "2. 제목: 앙코르 내 인생\n",
      "   저자: 신동흔, 김수혜, 김미리, 김신영\n",
      "   카테고리: 어문학\n",
      "\n",
      "3. 제목: 천개의 파랑\n",
      "   저자: 천선란\n",
      "   카테고리: 어문학\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print_recommendation_result(result, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"재미있는 소설 추천해줘\"와 같은 추상적인 질문에도 답변하였지만, 벡터db에서 유사도로 추천된 도서 리스트가 아쉬웠다.\n",
    "\n",
    "추천된 도서 리스트 중에는 비교적 질문과 가까운 도서를 추천하였다. \n",
    "\n",
    "output 길이 제한으로 result가 중간에 중단되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"재미있는 소설 추천해줘\"\n",
    "result = get_book_recommendation_from_gpt(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📚 도서 추천 결과\n",
      "================================================================================\n",
      "\n",
      "💭 질문:\n",
      "재미있는 소설 추천해줘\n",
      "\n",
      "📝 답변:\n",
      "재미있는 소설을 추천하기 위해 제시된 도서들의 난이도, 내용, 특징을 비교 분석해보겠습니다. 1. **도서 비교 분석**: - **『옛그림 속\n",
      "양반의 한평생』 - 허인욱**: 이 책은 인문과학 분야로, 조선시대 양반들의 삶을 풍속화와 함께 설명하는 내용입니다. 역사적 사실과 사회적\n",
      "맥락에 대한 깊은 이해를 제공하지만, 소설이 아닌 비소설이기 때문에 이야기의 흡입력이나 긴장감은 상대적으로 낮습니다. - **『그 무렵\n",
      "누군가』 - 히가시노 게이고**: 일본의 베스트셀러 작가 히가시노 게이고의 단편소설 모음집으로, 다양한 주제와 서스펜스를 담고 있습니다. 특히\n",
      "'아빠, 안녕'과 같은 몽환적인 소재와 '수수께끼가 가득'처럼 사회적 비판을 담은 이야기가 있어 흥미진진합니다. 짧은 분량의 여러 이야기를\n",
      "통해 긴장감과 재미를 느낄 수 있습니다. - **『도시를 걷는 시간』 - 김별아**: 어문학 장르로 서울 시내의 조선시대 표석을 탐방하며\n",
      "과거와 현재를 연결하는 에세이입니다. 역사적 요소와 도시 탐방에 중점을 두고 있지만, 소설적인 이야기 전개나 스릴이 부족하여 재미를 중시하는\n",
      "독자에게는 다소 지루할 수 있습니다. 2. **추천 도서 선정**: 질문자가 \"재미있는 소설\"을 요청한 만큼, 문학적 재미와 긴장감을 제공하는\n",
      "작품이 필요합니다. 따라서 히가시노 게이고의 『그 무렵 누군가』가 가장 적합한 선택입니다. 이 책은 단편소설 모음으로 다양한 이야기들이\n",
      "포함되어 있어 독자가 쉽게 접근하고 즐길 수 있으며, 작가 특유의 서스펜스와 극적 재미는 많은 독자들에게 호평받고 있습니다. 3. **추천\n",
      "도서 정보**: - **제목**: 그 무렵 누군가 - **저자**: 히가시노 게이고 이 책을 통해 여름의 더\n",
      "\n",
      "📚 검색된 유사 도서 (상위 3개):\n",
      "\n",
      "1. 제목: 옛그림 속 양반의 한평생\n",
      "   저자: 허인욱\n",
      "   카테고리: 인문과학\n",
      "\n",
      "2. 제목: 그 무렵 누군가\n",
      "   저자: 히가시노 게이고 \n",
      "   카테고리: 어문학\n",
      "\n",
      "3. 제목: 도시를 걷는 시간\n",
      "   저자: 김별아\n",
      "   카테고리: 어문학\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print_recommendation_result(result, question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
